Script started on 2024-12-25 19:59:00+0800
[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/coursework/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°2 [39m!1 [39m?1[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m¬∑¬∑[0m[49m[30m [0m[30m[49m[39mÓúº  base[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mwith [0m[49m[39mycm@x86_64-conda-linux-gnu[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mat [0m[49m[39mÔÄó  19:59:00[0m[49m[39m[0m[49m[39m[0m[49m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004hCCUDA_VISIBLE_DEVICES=0,3,4,7 python train_to_one_res.py --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res [K --data_dir data_saves/bzM[8C[32mp[32my[32mt[32mh[32mo[32mn[39m [4mt[4mr[4ma[4mi[4mn[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m_[4mr[4me[4ms[4m.[4mp[4my[24m[1B[47D[4md[4ma[4mt[4ma[4m_[4ms[4ma[4mv[4me[4ms[4m/[4mb[4mz[4mn[24mM[22D[3mC[3mU[3mD[3mA[3m_[3mV[3mI[3mS[3mI[3mB[3mL[3mE[3m_[3mD[3mE[3mV[3mI[3mC[3mE[3mS[3m=[3m0[3m,[3m3[3m,[3m4[3m,[3m7[3m [39m[3mp[39m[3my[39m[3mt[39m[3mh[39m[3mo[39m[3mn[3m [24m[3mt[24m[3mr[24m[3ma[24m[3mi[24m[3mn[24m[3m_[24m[3mt[24m[3mo[24m[3m_[24m[3mo[24m[3mn[24m[3me[24m[3m_[24m[3mr[24m[3me[24m[3ms[24m[3m.[24m[3mp[24m[3my[3m [3m-[3m-[3mm[3mo[3md[3me[3ml[3m_[3md[3mi[3mr[3m [3m.[3m/[3me[3mx[3mp[3ms[3m/[3mb[3mz[3mn[3m_[3mm[3mo[3md[3me[3ml[3m_[3mr[3me[3ms[3m [3m-[3m-[3mt[3me[3ms[3mt[3m_[3md[3mi[3mr[3m [3m.[3m/[3me[3mx[3mp[3ms[3m/[3mb[3mz[3mn[3m_[3mt[3me[3ms[3mt[3m_[3mr[3me[3ms[3m [3m-[3m-[3md[3ma[3mt[3ma[3m_[3md[3mi[3mr[3m [24m[3md[24m[3ma[24m[3mt[24m[3ma[24m[3m_[24m[3ms[24m[3ma[24m[3mv[24m[3me[24m[3ms[24m[3m/[24m[3mb[24m[3mz[24m[3mn[23mM[22D[23mC[23mU[23mD[23mA[23m_[23mV[23mI[23mS[23mI[23mB[23mL[23mE[23m_[23mD[23mE[23mV[23mI[23mC[23mE[23mS[23m=[23m0[23m,[23m3[23m,[23m4[23m,[23m7[23m [23mp[23my[23mt[23mh[23mo[23mn[23m [23mt[23mr[23ma[23mi[23mn[23m_[23mt[23mo[23m_[23mo[23mn[23me[23m_[23mr[23me[23ms[23m.[23mp[23my[23m [23m-[23m-[23mm[23mo[23md[23me[23ml[23m_[23md[23mi[23mr[23m [23m.[23m/[23me[23mx[23mp[23ms[23m/[23mb[23mz[23mn[23m_[23mm[23mo[23md[23me[23ml[23m_[23mr[23me[23ms[23m [23m-[23m-[23mt[23me[23ms[23mt[23m_[23md[23mi[23mr[23m [23m.[23m/[23me[23mx[23mp[23ms[23m/[23mb[23mz[23mn[23m_[23mt[23me[23ms[23mt[23m_[23mr[23me[23ms [23m-[23m-[23md[23ma[23mt[23ma[23m_[23md[23mi[23mr[23m [23md[23ma[23mt[23ma[23m_[23ms[23ma[23mv[23me[23ms[23m/[23mb[23mz[23mnM[7C[32mp[32my[32mt[32mh[32mo[32mn[39m [4mt[4mr[4ma[4mi[4mn[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m_[4mr[4me[4ms[4m.[4mp[4my[24m[1B[47D[4md[4ma[4mt[4ma[4m_[4ms[4ma[4mv[4me[4ms[4m/[4mb[4mz[4mn[24m[?1l>[?25l[?2004lMM[0m[23m[24m[J[0m[49m[23m[24m[39m‚ùØ[0m[49m[39m[23m[24m CUDA_VISIBLE_DEVICES=0,3,4,7 [32mpython[39m [4mtrain_to_one_res.py[24m --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res --data_dir [4mdata_saves/bzn[24m[K[?25h
kpython\Traceback (most recent call last):
  File "/home/ycm/repos/coursework/dpss-exp3-VC-BNF/train_to_one_res.py", line 2, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/coursework/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°2 [39m!1 [39m?1[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m¬∑¬∑[0m[49m[30m [0m[30m[49m[39mÓúº  base[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mwith [0m[49m[39mycm@x86_64-conda-linux-gnu[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mat [0m[49m[39mÔÄó  19:59:02[0m[49m[39m[0m[49m[39m[0m[49m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004h[4mc[24m[4mc[24mapture-pane -p -S - > file.txtÔºåÁÑ∂ÂêéÊåâÂõûËΩ¶„ÄÇËøôÈáåÁöÑ -p ÂèÇÊï∞Ë°®Á§∫ÊâìÂç∞ÊçïËé∑ÁöÑÁ™óÊ†ºÂÜÖÂÆπÔºå-S - Ë°®Á§∫‰ªéÂΩìÂâçÁ™óÊ†ºÁöÑÂºÄÂßã‰ΩçÁΩÆÂºÄÂßã~[116D[4mc[4mo[24m                                                                                                                   [115Dnda activate dpss[17D[4mc[4mo[4mn[24m[24m[1m[31mc[24m[1m[31mo[24m[1m[31mn[1m[31md[0m[39m[0m[32mc[0m[32mo[0m[32mn[0m[32md[32ma[39m[14C[?1l>[?25l[?2004lM[0m[23m[24m[J[0m[49m[23m[24m[39m‚ùØ[0m[49m[39m[23m[24m [32mconda[39m activate dpss[K[?25h
kconda\[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/coursework/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°2 [39m!1 [39m?1[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m¬∑¬∑[0m[49m[30m [0m[30m[49m[39mÓúº  dpss[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mwith [0m[49m[39mycm@x86_64-conda-linux-gnu[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mat [0m[49m[39mÔÄó  19:59:05[0m[49m[39m[0m[49m[39m[0m[49m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004hCCUDA_VISIBLE_DEVICES=0,3,4,7 python train_to_one_res.py --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res [K --data_dir data_saves/bzM[8C[32mp[32my[32mt[32mh[32mo[32mn[39m [4mt[4mr[4ma[4mi[4mn[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m_[4mr[4me[4ms[4m.[4mp[4my[24m[1B[47D[4md[4ma[4mt[4ma[4m_[4ms[4ma[4mv[4me[4ms[4m/[4mb[4mz[4mn[24mM[22D[3mC[3mU[3mD[3mA[3m_[3mV[3mI[3mS[3mI[3mB[3mL[3mE[3m_[3mD[3mE[3mV[3mI[3mC[3mE[3mS[3m=[3m0[3m,[3m3[3m,[3m4[3m,[3m7[3m [39m[3mp[39m[3my[39m[3mt[39m[3mh[39m[3mo[39m[3mn[3m [24m[3mt[24m[3mr[24m[3ma[24m[3mi[24m[3mn[24m[3m_[24m[3mt[24m[3mo[24m[3m_[24m[3mo[24m[3mn[24m[3me[24m[3m_[24m[3mr[24m[3me[24m[3ms[24m[3m.[24m[3mp[24m[3my[3m [3m-[3m-[3mm[3mo[3md[3me[3ml[3m_[3md[3mi[3mr[3m [3m.[3m/[3me[3mx[3mp[3ms[3m/[3mb[3mz[3mn[3m_[3mm[3mo[3md[3me[3ml[3m_[3mr[3me[3ms[3m [3m-[3m-[3mt[3me[3ms[3mt[3m_[3md[3mi[3mr[3m [3m.[3m/[3me[3mx[3mp[3ms[3m/[3mb[3mz[3mn[3m_[3mt[3me[3ms[3mt[3m_[3mr[3me[3ms[3m [3m-[3m-[3md[3ma[3mt[3ma[3m_[3md[3mi[3mr[3m [24m[3md[24m[3ma[24m[3mt[24m[3ma[24m[3m_[24m[3ms[24m[3ma[24m[3mv[24m[3me[24m[3ms[24m[3m/[24m[3mb[24m[3mz[24m[3mn[23mM[22D[23mC[23mU[23mD[23mA[23m_[23mV[23mI[23mS[23mI[23mB[23mL[23mE[23m_[23mD[23mE[23mV[23mI[23mC[23mE[23mS[23m=[23m0[23m,[23m3[23m,[23m4[23m,[23m7[23m [23mp[23my[23mt[23mh[23mo[23mn[23m [23mt[23mr[23ma[23mi[23mn[23m_[23mt[23mo[23m_[23mo[23mn[23me[23m_[23mr[23me[23ms[23m.[23mp[23my[23m [23m-[23m-[23mm[23mo[23md[23me[23ml[23m_[23md[23mi[23mr[23m [23m.[23m/[23me[23mx[23mp[23ms[23m/[23mb[23mz[23mn[23m_[23mm[23mo[23md[23me[23ml[23m_[23mr[23me[23ms[23m [23m-[23m-[23mt[23me[23ms[23mt[23m_[23md[23mi[23mr[23m [23m.[23m/[23me[23mx[23mp[23ms[23m/[23mb[23mz[23mn[23m_[23mt[23me[23ms[23mt[23m_[23mr[23me[23ms [23m-[23m-[23md[23ma[23mt[23ma[23m_[23md[23mi[23mr[23m [23md[23ma[23mt[23ma[23m_[23ms[23ma[23mv[23me[23ms[23m/[23mb[23mz[23mnM[7C[32mp[32my[32mt[32mh[32mo[32mn[39m [4mt[4mr[4ma[4mi[4mn[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m_[4mr[4me[4ms[4m.[4mp[4my[24m[1B[47D[4md[4ma[4mt[4ma[4m_[4ms[4ma[4mv[4me[4ms[4m/[4mb[4mz[4mn[24m[?1l>[?25l[?2004lMM[0m[23m[24m[J[0m[49m[23m[24m[39m‚ùØ[0m[49m[39m[23m[24m CUDA_VISIBLE_DEVICES=0,3,4,7 [32mpython[39m [4mtrain_to_one_res.py[24m --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res --data_dir [4mdata_saves/bzn[24m[K[?25h
kpython\Traceback (most recent call last):
  File "train_to_one_res.py", line 7, in <module>
    from models import BLSTMResConversionModel
ImportError: cannot import name 'BLSTMResConversionModel' from 'models' (/home/ycm/repos/coursework/dpss-exp3-VC-BNF/models/__init__.py)
[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/coursework/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°2 [39m!1 [39m?1[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m¬∑¬∑[0m[49m[30m [0m[30m[49m[39mÓúº  dpss[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mwith [0m[49m[39mycm@x86_64-conda-linux-gnu[0m[49m[39m[0m[49m[39m[0m[49m[39m [39mat [0m[49m[39mÔÄó  19:59:07[0m[49m[39m[0m[49m[39m[0m[49m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004hCUDA_VISIBLE_DEVICES=0,3,4,7 [32mpython[39m [4mtrain_to_one_res.py[24m --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res --data_dir [4mdata_saves/bzn[24m[K[?1l>[?25l[?2004lMM[0m[23m[24m[J[0m[49m[23m[24m[39m‚ùØ[0m[49m[39m[23m[24m CUDA_VISIBLE_DEVICES=0,3,4,7 [32mpython[39m [4mtrain_to_one_res.py[24m --model_dir ./exps/bzn_model_res --test_dir ./exps/bzn_test_res --data_dir [4mdata_saves/bzn[24m[K[?25h
kpython\Train on cuda:0
[1,     1] Training loss: 1.70854
[1,     2] Training loss: 1.18361
[1,     3] Training loss: 0.78788
[1,     4] Training loss: 0.72738
[1,     5] Training loss: 0.52615
[1,     6] Training loss: 0.33979
[1,     7] Training loss: 0.26044
[1,     8] Training loss: 0.20778
[1,     9] Training loss: 0.13660
[1,    10] Training loss: 0.11939
[1,    11] Training loss: 0.12271
[1,    12] Training loss: 0.09479
[1,    13] Training loss: 0.08709
[1,    14] Training loss: 0.08078
[1,    15] Training loss: 0.06916
[1,    16] Training loss: 0.05846
[1,    17] Training loss: 0.05600
[1,    18] Training loss: 0.05670
[1,    19] Training loss: 0.05427
[1,    20] Training loss: 0.04999
[1,    21] Training loss: 0.04872
[1,    22] Training loss: 0.04349
[1,    23] Training loss: 0.04169
[1,    24] Training loss: 0.03995
[1,    25] Training loss: 0.03916
[1,    26] Training loss: 0.03845
[1,    27] Training loss: 0.03795
[1,    28] Training loss: 0.03617
[1,    29] Training loss: 0.03497
[1,    30] Training loss: 0.03297
[1,    31] Training loss: 0.03173
[1,    32] Training loss: 0.03128
[1,    33] Training loss: 0.03252
[1,    34] Training loss: 0.03113
[1,    35] Training loss: 0.02988
[1,    36] Training loss: 0.03019
[1,    37] Training loss: 0.02792
[1,    38] Training loss: 0.02710
[1,    39] Training loss: 0.02755
[1,    40] Training loss: 0.02743
[1,    41] Training loss: 0.02773
[1,    42] Training loss: 0.02669
[1,    43] Training loss: 0.02502
[1,    44] Training loss: 0.02469
[1,    45] Training loss: 0.02526
[1,    46] Training loss: 0.02412
[1,    47] Training loss: 0.02487
[1,    48] Training loss: 0.02362
[1,    49] Training loss: 0.02272
[1,    50] Training loss: 0.02335
[1,    51] Training loss: 0.02315
[1,    52] Training loss: 0.02241
[1,    53] Training loss: 0.02230
[1,    54] Training loss: 0.02302
[1,    55] Training loss: 0.02133
[1,    56] Training loss: 0.02174
[1,    57] Training loss: 0.02216
[1] Validation loss: 0.02156
[2,     1] Training loss: 0.02115
[2,     2] Training loss: 0.02143
[2,     3] Training loss: 0.02077
[2,     4] Training loss: 0.02163
[2,     5] Training loss: 0.02034
[2,     6] Training loss: 0.01941
[2,     7] Training loss: 0.01968
[2,     8] Training loss: 0.02030
[2,     9] Training loss: 0.01969
[2,    10] Training loss: 0.02038
[2,    11] Training loss: 0.02002
[2,    12] Training loss: 0.01958
[2,    13] Training loss: 0.01942
[2,    14] Training loss: 0.01999
[2,    15] Training loss: 0.01944
[2,    16] Training loss: 0.01896
[2,    17] Training loss: 0.01902
[2,    18] Training loss: 0.01852
[2,    19] Training loss: 0.01871
[2,    20] Training loss: 0.01888
[2,    21] Training loss: 0.01817
[2,    22] Training loss: 0.01788
[2,    23] Training loss: 0.01838
[2,    24] Training loss: 0.01790
[2,    25] Training loss: 0.01773
[2,    26] Training loss: 0.01782
[2,    27] Training loss: 0.01815
[2,    28] Training loss: 0.01761
[2,    29] Training loss: 0.01777
[2,    30] Training loss: 0.01746
[2,    31] Training loss: 0.01750
[2,    32] Training loss: 0.01799
[2,    33] Training loss: 0.01680
[2,    34] Training loss: 0.01725
[2,    35] Training loss: 0.01765
[2,    36] Training loss: 0.01717
[2,    37] Training loss: 0.01742
[2,    38] Training loss: 0.01735
[2,    39] Training loss: 0.01702
[2,    40] Training loss: 0.01689
[2,    41] Training loss: 0.01721
[2,    42] Training loss: 0.01698
[2,    43] Training loss: 0.01677
[2,    44] Training loss: 0.01686
[2,    45] Training loss: 0.01686
[2,    46] Training loss: 0.01649
[2,    47] Training loss: 0.01645
[2,    48] Training loss: 0.01677
[2,    49] Training loss: 0.01620
[2,    50] Training loss: 0.01651
[2,    51] Training loss: 0.01633
[2,    52] Training loss: 0.01640
[2,    53] Training loss: 0.01590
[2,    54] Training loss: 0.01607
[2,    55] Training loss: 0.01626
[2,    56] Training loss: 0.01610
[2,    57] Training loss: 0.01645
[2] Validation loss: 0.01584
[3,     1] Training loss: 0.01615
[3,     2] Training loss: 0.01563
[3,     3] Training loss: 0.01544
[3,     4] Training loss: 0.01549
[3,     5] Training loss: 0.01570
[3,     6] Training loss: 0.01553
[3,     7] Training loss: 0.01594
[3,     8] Training loss: 0.01557
[3,     9] Training loss: 0.01521
[3,    10] Training loss: 0.01611
[3,    11] Training loss: 0.01598
[3,    12] Training loss: 0.01579
[3,    13] Training loss: 0.01515
[3,    14] Training loss: 0.01560
[3,    15] Training loss: 0.01503
[3,    16] Training loss: 0.01593
[3,    17] Training loss: 0.01499
[3,    18] Training loss: 0.01517
[3,    19] Training loss: 0.01549
[3,    20] Training loss: 0.01493
[3,    21] Training loss: 0.01509
[3,    22] Training loss: 0.01499
[3,    23] Training loss: 0.01480
[3,    24] Training loss: 0.01478
[3,    25] Training loss: 0.01448
[3,    26] Training loss: 0.01475
[3,    27] Training loss: 0.01474
[3,    28] Training loss: 0.01491
[3,    29] Training loss: 0.01430
[3,    30] Training loss: 0.01476
[3,    31] Training loss: 0.01502
[3,    32] Training loss: 0.01504
[3,    33] Training loss: 0.01481
[3,    34] Training loss: 0.01447
[3,    35] Training loss: 0.01456
[3,    36] Training loss: 0.01518
[3,    37] Training loss: 0.01439
[3,    38] Training loss: 0.01470
[3,    39] Training loss: 0.01506
[3,    40] Training loss: 0.01414
[3,    41] Training loss: 0.01462
[3,    42] Training loss: 0.01530
[3,    43] Training loss: 0.01417
[3,    44] Training loss: 0.01516
[3,    45] Training loss: 0.01438
[3,    46] Training loss: 0.01468
[3,    47] Training loss: 0.01450
[3,    48] Training loss: 0.01375
[3,    49] Training loss: 0.01374
[3,    50] Training loss: 0.01420
[3,    51] Training loss: 0.01430
[3,    52] Training loss: 0.01413
[3,    53] Training loss: 0.01412
[3,    54] Training loss: 0.01446
[3,    55] Training loss: 0.01424
[3,    56] Training loss: 0.01396
[3,    57] Training loss: 0.01349
[3] Validation loss: 0.01466
[4,     1] Training loss: 0.01419
[4,     2] Training loss: 0.01420
[4,     3] Training loss: 0.01412
[4,     4] Training loss: 0.01333
[4,     5] Training loss: 0.01395
[4,     6] Training loss: 0.01387
[4,     7] Training loss: 0.01402
[4,     8] Training loss: 0.01419
[4,     9] Training loss: 0.01432
[4,    10] Training loss: 0.01392
[4,    11] Training loss: 0.01359
[4,    12] Training loss: 0.01417
[4,    13] Training loss: 0.01407
[4,    14] Training loss: 0.01404
[4,    15] Training loss: 0.01338
[4,    16] Training loss: 0.01403
[4,    17] Training loss: 0.01371
[4,    18] Training loss: 0.01385
[4,    19] Training loss: 0.01348
[4,    20] Training loss: 0.01335
[4,    21] Training loss: 0.01361
[4,    22] Training loss: 0.01314
[4,    23] Training loss: 0.01353
[4,    24] Training loss: 0.01363
[4,    25] Training loss: 0.01363
[4,    26] Training loss: 0.01335
[4,    27] Training loss: 0.01368
[4,    28] Training loss: 0.01354
[4,    29] Training loss: 0.01328
[4,    30] Training loss: 0.01360
[4,    31] Training loss: 0.01329
[4,    32] Training loss: 0.01314
[4,    33] Training loss: 0.01398
[4,    34] Training loss: 0.01384
[4,    35] Training loss: 0.01338
[4,    36] Training loss: 0.01426
[4,    37] Training loss: 0.01456
[4,    38] Training loss: 0.01345
[4,    39] Training loss: 0.01371
[4,    40] Training loss: 0.01324
[4,    41] Training loss: 0.01393
[4,    42] Training loss: 0.01353
[4,    43] Training loss: 0.01353
[4,    44] Training loss: 0.01302
[4,    45] Training loss: 0.01322
[4,    46] Training loss: 0.01309
[4,    47] Training loss: 0.01387
[4,    48] Training loss: 0.01386
[4,    49] Training loss: 0.01312
[4,    50] Training loss: 0.01300
[4,    51] Training loss: 0.01321
[4,    52] Training loss: 0.01326
[4,    53] Training loss: 0.01325
[4,    54] Training loss: 0.01376
[4,    55] Training loss: 0.01417
[4,    56] Training loss: 0.01356
[4,    57] Training loss: 0.01353
[4] Validation loss: 0.01325
[5,     1] Training loss: 0.01353
[5,     2] Training loss: 0.01376
[5,     3] Training loss: 0.01300
[5,     4] Training loss: 0.01416
[5,     5] Training loss: 0.01505
[5,     6] Training loss: 0.01281
[5,     7] Training loss: 0.01383
[5,     8] Training loss: 0.01472
[5,     9] Training loss: 0.01270
[5,    10] Training loss: 0.01389
[5,    11] Training loss: 0.01416
[5,    12] Training loss: 0.01308
[5,    13] Training loss: 0.01363
[5,    14] Training loss: 0.01323
[5,    15] Training loss: 0.01332
[5,    16] Training loss: 0.01298
[5,    17] Training loss: 0.01284
[5,    18] Training loss: 0.01365
[5,    19] Training loss: 0.01358
[5,    20] Training loss: 0.01351
[5,    21] Training loss: 0.01310
[5,    22] Training loss: 0.01254
[5,    23] Training loss: 0.01319
[5,    24] Training loss: 0.01325
[5,    25] Training loss: 0.01319
[5,    26] Training loss: 0.01281
[5,    27] Training loss: 0.01281
[5,    28] Training loss: 0.01265
[5,    29] Training loss: 0.01250
[5,    30] Training loss: 0.01310
[5,    31] Training loss: 0.01293
[5,    32] Training loss: 0.01268
[5,    33] Training loss: 0.01260
[5,    34] Training loss: 0.01284
[5,    35] Training loss: 0.01267
[5,    36] Training loss: 0.01234
[5,    37] Training loss: 0.01277
[5,    38] Training loss: 0.01246
[5,    39] Training loss: 0.01247
[5,    40] Training loss: 0.01267
[5,    41] Training loss: 0.01242
[5,    42] Training loss: 0.01315
[5,    43] Training loss: 0.01254
[5,    44] Training loss: 0.01213
[5,    45] Training loss: 0.01278
[5,    46] Training loss: 0.01254
[5,    47] Training loss: 0.01282
[5,    48] Training loss: 0.01243
[5,    49] Training loss: 0.01217
[5,    50] Training loss: 0.01246
[5,    51] Training loss: 0.01222
[5,    52] Training loss: 0.01268
[5,    53] Training loss: 0.01245
[5,    54] Training loss: 0.01304
[5,    55] Training loss: 0.01257
[5,    56] Training loss: 0.01267
[5,    57] Training loss: 0.01306
[5] Validation loss: 0.01265
[6,     1] Training loss: 0.01240
[6,     2] Training loss: 0.01232
[6,     3] Training loss: 0.01216
[6,     4] Training loss: 0.01238
[6,     5] Training loss: 0.01263
[6,     6] Training loss: 0.01260
[6,     7] Training loss: 0.01264
[6,     8] Training loss: 0.01242
[6,     9] Training loss: 0.01275
[6,    10] Training loss: 0.01233
[6,    11] Training loss: 0.01301
[6,    12] Training loss: 0.01369
[6,    13] Training loss: 0.01237
[6,    14] Training loss: 0.01301
[6,    15] Training loss: 0.01317
[6,    16] Training loss: 0.01207
[6,    17] Training loss: 0.01371
[6,    18] Training loss: 0.01315
[6,    19] Training loss: 0.01273
[6,    20] Training loss: 0.01323
[6,    21] Training loss: 0.01294
[6,    22] Training loss: 0.01244
[6,    23] Training loss: 0.01246
[6,    24] Training loss: 0.01266
[6,    25] Training loss: 0.01265
[6,    26] Training loss: 0.01276
[6,    27] Training loss: 0.01274
[6,    28] Training loss: 0.01210
[6,    29] Training loss: 0.01231
[6,    30] Training loss: 0.01247
[6,    31] Training loss: 0.01226
[6,    32] Training loss: 0.01269
[6,    33] Training loss: 0.01296
[6,    34] Training loss: 0.01290
[6,    35] Training loss: 0.01240
[6,    36] Training loss: 0.01244
[6,    37] Training loss: 0.01171
[6,    38] Training loss: 0.01257
[6,    39] Training loss: 0.01269
[6,    40] Training loss: 0.01262
[6,    41] Training loss: 0.01204
[6,    42] Training loss: 0.01256
[6,    43] Training loss: 0.01225
[6,    44] Training loss: 0.01282
[6,    45] Training loss: 0.01220
[6,    46] Training loss: 0.01206
[6,    47] Training loss: 0.01252
[6,    48] Training loss: 0.01280
[6,    49] Training loss: 0.01198
[6,    50] Training loss: 0.01249
[6,    51] Training loss: 0.01281
[6,    52] Training loss: 0.01276
[6,    53] Training loss: 0.01237
[6,    54] Training loss: 0.01203
[6,    55] Training loss: 0.01240
[6,    56] Training loss: 0.01220
[6,    57] Training loss: 0.01180
[6] Validation loss: 0.01215
[7,     1] Training loss: 0.01214
[7,     2] Training loss: 0.01253
[7,     3] Training loss: 0.01207
[7,     4] Training loss: 0.01202
[7,     5] Training loss: 0.01234
[7,     6] Training loss: 0.01203
[7,     7] Training loss: 0.01206
[7,     8] Training loss: 0.01233
[7,     9] Training loss: 0.01165
[7,    10] Training loss: 0.01228
[7,    11] Training loss: 0.01174
[7,    12] Training loss: 0.01226
[7,    13] Training loss: 0.01313
[7,    14] Training loss: 0.01273
[7,    15] Training loss: 0.01217
[7,    16] Training loss: 0.01189
[7,    17] Training loss: 0.01244
[7,    18] Training loss: 0.01195
[7,    19] Training loss: 0.01188
[7,    20] Training loss: 0.01219
[7,    21] Training loss: 0.01231
[7,    22] Training loss: 0.01208
[7,    23] Training loss: 0.01138
[7,    24] Training loss: 0.01168
[7,    25] Training loss: 0.01212
[7,    26] Training loss: 0.01198
[7,    27] Training loss: 0.01210
[7,    28] Training loss: 0.01156
[7,    29] Training loss: 0.01233
[7,    30] Training loss: 0.01193
[7,    31] Training loss: 0.01193
[7,    32] Training loss: 0.01203
[7,    33] Training loss: 0.01172
[7,    34] Training loss: 0.01198
[7,    35] Training loss: 0.01167
[7,    36] Training loss: 0.01176
[7,    37] Training loss: 0.01212
[7,    38] Training loss: 0.01187
[7,    39] Training loss: 0.01176
[7,    40] Training loss: 0.01193
[7,    41] Training loss: 0.01183
[7,    42] Training loss: 0.01170
[7,    43] Training loss: 0.01282
[7,    44] Training loss: 0.01223
[7,    45] Training loss: 0.01173
[7,    46] Training loss: 0.01193
[7,    47] Training loss: 0.01177
[7,    48] Training loss: 0.01181
[7,    49] Training loss: 0.01253
[7,    50] Training loss: 0.01269
[7,    51] Training loss: 0.01233
[7,    52] Training loss: 0.01215
[7,    53] Training loss: 0.01202
[7,    54] Training loss: 0.01201
[7,    55] Training loss: 0.01167
[7,    56] Training loss: 0.01215
[7,    57] Training loss: 0.01131
[7] Validation loss: 0.01241
[8,     1] Training loss: 0.01246
[8,     2] Training loss: 0.01196
[8,     3] Training loss: 0.01201
[8,     4] Training loss: 0.01189
[8,     5] Training loss: 0.01193
[8,     6] Training loss: 0.01185
[8,     7] Training loss: 0.01173
[8,     8] Training loss: 0.01138
[8,     9] Training loss: 0.01202
[8,    10] Training loss: 0.01137
[8,    11] Training loss: 0.01153
[8,    12] Training loss: 0.01168
[8,    13] Training loss: 0.01182
[8,    14] Training loss: 0.01163
[8,    15] Training loss: 0.01210
[8,    16] Training loss: 0.01198
[8,    17] Training loss: 0.01357
[8,    18] Training loss: 0.01423
[8,    19] Training loss: 0.01388
[8,    20] Training loss: 0.01224
[8,    21] Training loss: 0.01173
[8,    22] Training loss: 0.01191
[8,    23] Training loss: 0.01148
[8,    24] Training loss: 0.01123
[8,    25] Training loss: 0.01225
[8,    26] Training loss: 0.01214
[8,    27] Training loss: 0.01166
[8,    28] Training loss: 0.01151
[8,    29] Training loss: 0.01286
[8,    30] Training loss: 0.01186
[8,    31] Training loss: 0.01177
[8,    32] Training loss: 0.01454
[8,    33] Training loss: 0.01494
[8,    34] Training loss: 0.01186
[8,    35] Training loss: 0.01229
[8,    36] Training loss: 0.01263
[8,    37] Training loss: 0.01169
[8,    38] Training loss: 0.01187
[8,    39] Training loss: 0.01197
[8,    40] Training loss: 0.01172
[8,    41] Training loss: 0.01174
[8,    42] Training loss: 0.01156
[8,    43] Training loss: 0.01150
[8,    44] Training loss: 0.01205
[8,    45] Training loss: 0.01137
[8,    46] Training loss: 0.01132
[8,    47] Training loss: 0.01190
[8,    48] Training loss: 0.01193
[8,    49] Training loss: 0.01143
[8,    50] Training loss: 0.01198
[8,    51] Training loss: 0.01123
[8,    52] Training loss: 0.01171
[8,    53] Training loss: 0.01131
[8,    54] Training loss: 0.01136
[8,    55] Training loss: 0.01158
[8,    56] Training loss: 0.01179
[8,    57] Training loss: 0.01077
[8] Validation loss: 0.01157
[9,     1] Training loss: 0.01142
[9,     2] Training loss: 0.01176
[9,     3] Training loss: 0.01141
[9,     4] Training loss: 0.01142
[9,     5] Training loss: 0.01178
[9,     6] Training loss: 0.01161
[9,     7] Training loss: 0.01117
[9,     8] Training loss: 0.01149
[9,     9] Training loss: 0.01170
[9,    10] Training loss: 0.01128
[9,    11] Training loss: 0.01176
[9,    12] Training loss: 0.01162
[9,    13] Training loss: 0.01129
[9,    14] Training loss: 0.01137
[9,    15] Training loss: 0.01153
[9,    16] Training loss: 0.01103
[9,    17] Training loss: 0.01109
[9,    18] Training loss: 0.01116
[9,    19] Training loss: 0.01106
[9,    20] Training loss: 0.01159
[9,    21] Training loss: 0.01130
[9,    22] Training loss: 0.01189
[9,    23] Training loss: 0.01137
[9,    24] Training loss: 0.01134
[9,    25] Training loss: 0.01146
[9,    26] Training loss: 0.01120
[9,    27] Training loss: 0.01160
[9,    28] Training loss: 0.01148
[9,    29] Training loss: 0.01129
[9,    30] Training loss: 0.01157
[9,    31] Training loss: 0.01120
[9,    32] Training loss: 0.01111
[9,    33] Training loss: 0.01134
[9,    34] Training loss: 0.01172
[9,    35] Training loss: 0.01172
[9,    36] Training loss: 0.01175
[9,    37] Training loss: 0.01116
[9,    38] Training loss: 0.01165
[9,    39] Training loss: 0.01132
[9,    40] Training loss: 0.01147
[9,    41] Training loss: 0.01196
[9,    42] Training loss: 0.01239
[9,    43] Training loss: 0.01105
[9,    44] Training loss: 0.01157
[9,    45] Training loss: 0.01147
[9,    46] Training loss: 0.01154
[9,    47] Training loss: 0.01172
[9,    48] Training loss: 0.01205
[9,    49] Training loss: 0.01181
[9,    50] Training loss: 0.01138
[9,    51] Training loss: 0.01194
[9,    52] Training loss: 0.01181
[9,    53] Training loss: 0.01099
[9,    54] Training loss: 0.01164
[9,    55] Training loss: 0.01111
[9,    56] Training loss: 0.01123
[9,    57] Training loss: 0.01187
[9] Validation loss: 0.01246
[10,     1] Training loss: 0.01261
[10,     2] Training loss: 0.01223
[10,     3] Training loss: 0.01194
[10,     4] Training loss: 0.01290
[10,     5] Training loss: 0.01274
[10,     6] Training loss: 0.01185
[10,     7] Training loss: 0.01301
[10,     8] Training loss: 0.01258
[10,     9] Training loss: 0.01151
[10,    10] Training loss: 0.01215
[10,    11] Training loss: 0.01160
[10,    12] Training loss: 0.01128
[10,    13] Training loss: 0.01160
[10,    14] Training loss: 0.01151
[10,    15] Training loss: 0.01152
[10,    16] Training loss: 0.01153
[10,    17] Training loss: 0.01121
[10,    18] Training loss: 0.01137
[10,    19] Training loss: 0.01163
[10,    20] Training loss: 0.01106
[10,    21] Training loss: 0.01155
[10,    22] Training loss: 0.01134
[10,    23] Training loss: 0.01159
[10,    24] Training loss: 0.01095
[10,    25] Training loss: 0.01166
[10,    26] Training loss: 0.01161
[10,    27] Training loss: 0.01129
[10,    28] Training loss: 0.01133
[10,    29] Training loss: 0.01195
[10,    30] Training loss: 0.01136
[10,    31] Training loss: 0.01101
[10,    32] Training loss: 0.01122
[10,    33] Training loss: 0.01117
[10,    34] Training loss: 0.01101
[10,    35] Training loss: 0.01108
[10,    36] Training loss: 0.01111
[10,    37] Training loss: 0.01070
[10,    38] Training loss: 0.01127
[10,    39] Training loss: 0.01105
[10,    40] Training loss: 0.01127
[10,    41] Training loss: 0.01130
[10,    42] Training loss: 0.01060
[10,    43] Training loss: 0.01090
[10,    44] Training loss: 0.01086
[10,    45] Training loss: 0.01112
[10,    46] Training loss: 0.01094
[10,    47] Training loss: 0.01106
[10,    48] Training loss: 0.01088
[10,    49] Training loss: 0.01099
[10,    50] Training loss: 0.01059
[10,    51] Training loss: 0.01100
[10,    52] Training loss: 0.01167
[10,    53] Training loss: 0.01118
[10,    54] Training loss: 0.01094
[10,    55] Training loss: 0.01134
[10,    56] Training loss: 0.01094
[10,    57] Training loss: 0.01175
[10] Validation loss: 0.01129
[11,     1] Training loss: 0.01135
[11,     2] Training loss: 0.01162
[11,     3] Training loss: 0.01116
[11,     4] Training loss: 0.01088
[11,     5] Training loss: 0.01131
[11,     6] Training loss: 0.01086
[11,     7] Training loss: 0.01111
[11,     8] Training loss: 0.01116
[11,     9] Training loss: 0.01059
[11,    10] Training loss: 0.01145
[11,    11] Training loss: 0.01112
[11,    12] Training loss: 0.01083
[11,    13] Training loss: 0.01116
[11,    14] Training loss: 0.01159
[11,    15] Training loss: 0.01094
[11,    16] Training loss: 0.01133
[11,    17] Training loss: 0.01107
[11,    18] Training loss: 0.01083
[11,    19] Training loss: 0.01157
[11,    20] Training loss: 0.01118
[11,    21] Training loss: 0.01076
[11,    22] Training loss: 0.01130
[11,    23] Training loss: 0.01097
[11,    24] Training loss: 0.01063
[11,    25] Training loss: 0.01150
[11,    26] Training loss: 0.01109
[11,    27] Training loss: 0.01079
[11,    28] Training loss: 0.01068
[11,    29] Training loss: 0.01086
[11,    30] Training loss: 0.01084
[11,    31] Training loss: 0.01104
[11,    32] Training loss: 0.01128
[11,    33] Training loss: 0.01110
[11,    34] Training loss: 0.01058
[11,    35] Training loss: 0.01098
[11,    36] Training loss: 0.01092
[11,    37] Training loss: 0.01100
[11,    38] Training loss: 0.01028
[11,    39] Training loss: 0.01079
[11,    40] Training loss: 0.01099
[11,    41] Training loss: 0.01099
[11,    42] Training loss: 0.01062
[11,    43] Training loss: 0.01100
[11,    44] Training loss: 0.01054
[11,    45] Training loss: 0.01072
[11,    46] Training loss: 0.01048
[11,    47] Training loss: 0.01070
[11,    48] Training loss: 0.01098
[11,    49] Training loss: 0.01116
[11,    50] Training loss: 0.01066
[11,    51] Training loss: 0.01061
[11,    52] Training loss: 0.01065
[11,    53] Training loss: 0.01070
[11,    54] Training loss: 0.01112
[11,    55] Training loss: 0.01127
[11,    56] Training loss: 0.01081
[11,    57] Training loss: 0.01093
[11] Validation loss: 0.01135
[12,     1] Training loss: 0.01167
[12,     2] Training loss: 0.01142
[12,     3] Training loss: 0.01121
[12,     4] Training loss: 0.01102
[12,     5] Training loss: 0.01148
[12,     6] Training loss: 0.01088
[12,     7] Training loss: 0.01059
[12,     8] Training loss: 0.01080
[12,     9] Training loss: 0.01088
[12,    10] Training loss: 0.01058
[12,    11] Training loss: 0.01066
[12,    12] Training loss: 0.01109
[12,    13] Training loss: 0.01047
[12,    14] Training loss: 0.01064
[12,    15] Training loss: 0.01093
[12,    16] Training loss: 0.01056
[12,    17] Training loss: 0.01046
[12,    18] Training loss: 0.01082
[12,    19] Training loss: 0.01108
[12,    20] Training loss: 0.01060
[12,    21] Training loss: 0.01074
[12,    22] Training loss: 0.01070
[12,    23] Training loss: 0.01090
[12,    24] Training loss: 0.01082
[12,    25] Training loss: 0.01089
[12,    26] Training loss: 0.01040
[12,    27] Training loss: 0.01039
[12,    28] Training loss: 0.01089
[12,    29] Training loss: 0.01088
[12,    30] Training loss: 0.01077
[12,    31] Training loss: 0.01060
[12,    32] Training loss: 0.01060
[12,    33] Training loss: 0.01068
[12,    34] Training loss: 0.01103
[12,    35] Training loss: 0.01093
[12,    36] Training loss: 0.01051
[12,    37] Training loss: 0.01031
[12,    38] Training loss: 0.01065
[12,    39] Training loss: 0.01066
[12,    40] Training loss: 0.01061
[12,    41] Training loss: 0.01007
[12,    42] Training loss: 0.01024
[12,    43] Training loss: 0.01047
[12,    44] Training loss: 0.01039
[12,    45] Training loss: 0.01077
[12,    46] Training loss: 0.01086
[12,    47] Training loss: 0.01034
[12,    48] Training loss: 0.01072
[12,    49] Training loss: 0.01065
[12,    50] Training loss: 0.01112
[12,    51] Training loss: 0.01093
[12,    52] Training loss: 0.01052
[12,    53] Training loss: 0.01043
[12,    54] Training loss: 0.01068
[12,    55] Training loss: 0.01023
[12,    56] Training loss: 0.01049
[12,    57] Training loss: 0.01062
[12] Validation loss: 0.01092
[13,     1] Training loss: 0.01061
[13,     2] Training loss: 0.01103
[13,     3] Training loss: 0.01018
[13,     4] Training loss: 0.01083
[13,     5] Training loss: 0.01027
[13,     6] Training loss: 0.01072
[13,     7] Training loss: 0.01122
[13,     8] Training loss: 0.01077
[13,     9] Training loss: 0.01083
[13,    10] Training loss: 0.01120
[13,    11] Training loss: 0.01047
[13,    12] Training loss: 0.01115
[13,    13] Training loss: 0.01114
[13,    14] Training loss: 0.01108
[13,    15] Training loss: 0.01078
[13,    16] Training loss: 0.01113
[13,    17] Training loss: 0.01075
[13,    18] Training loss: 0.01059
[13,    19] Training loss: 0.01163
[13,    20] Training loss: 0.01089
[13,    21] Training loss: 0.01070
[13,    22] Training loss: 0.01103
[13,    23] Training loss: 0.01058
[13,    24] Training loss: 0.01047
[13,    25] Training loss: 0.01031
[13,    26] Training loss: 0.01066
[13,    27] Training loss: 0.01090
[13,    28] Training loss: 0.01054
[13,    29] Training loss: 0.01094
[13,    30] Training loss: 0.01023
[13,    31] Training loss: 0.01013
[13,    32] Training loss: 0.01059
[13,    33] Training loss: 0.01002
[13,    34] Training loss: 0.01005
[13,    35] Training loss: 0.01045
[13,    36] Training loss: 0.01023
[13,    37] Training loss: 0.01101
[13,    38] Training loss: 0.01105
[13,    39] Training loss: 0.01062
[13,    40] Training loss: 0.01080
[13,    41] Training loss: 0.01054
[13,    42] Training loss: 0.01100
[13,    43] Training loss: 0.01036
[13,    44] Training loss: 0.01029
[13,    45] Training loss: 0.01073
[13,    46] Training loss: 0.01029
[13,    47] Training loss: 0.01028
[13,    48] Training loss: 0.01038
[13,    49] Training loss: 0.01016
[13,    50] Training loss: 0.01101
[13,    51] Training loss: 0.01090
[13,    52] Training loss: 0.01007
[13,    53] Training loss: 0.01106
[13,    54] Training loss: 0.01043
[13,    55] Training loss: 0.01013
[13,    56] Training loss: 0.01086
[13,    57] Training loss: 0.01034
[13] Validation loss: 0.01098
[14,     1] Training loss: 0.01062
[14,     2] Training loss: 0.01045
[14,     3] Training loss: 0.01035
[14,     4] Training loss: 0.01039
[14,     5] Training loss: 0.01017
[14,     6] Training loss: 0.01003
[14,     7] Training loss: 0.01020
[14,     8] Training loss: 0.01057
[14,     9] Training loss: 0.01050
[14,    10] Training loss: 0.01097
[14,    11] Training loss: 0.01072
[14,    12] Training loss: 0.01027
[14,    13] Training loss: 0.01004
[14,    14] Training loss: 0.01072
[14,    15] Training loss: 0.01034
[14,    16] Training loss: 0.01136
[14,    17] Training loss: 0.01116
[14,    18] Training loss: 0.01074
[14,    19] Training loss: 0.01036
[14,    20] Training loss: 0.01042
[14,    21] Training loss: 0.01069
[14,    22] Training loss: 0.01048
[14,    23] Training loss: 0.01032
[14,    24] Training loss: 0.01029
[14,    25] Training loss: 0.01023
[14,    26] Training loss: 0.01031
[14,    27] Training loss: 0.00986
[14,    28] Training loss: 0.01054
[14,    29] Training loss: 0.01049
[14,    30] Training loss: 0.00987
[14,    31] Training loss: 0.01044
[14,    32] Training loss: 0.00973
[14,    33] Training loss: 0.01022
[14,    34] Training loss: 0.01014
[14,    35] Training loss: 0.00993
[14,    36] Training loss: 0.00966
[14,    37] Training loss: 0.01028
[14,    38] Training loss: 0.01024
[14,    39] Training loss: 0.01047
[14,    40] Training loss: 0.01012
[14,    41] Training loss: 0.01041
[14,    42] Training loss: 0.01073
[14,    43] Training loss: 0.01055
[14,    44] Training loss: 0.01134
[14,    45] Training loss: 0.01022
[14,    46] Training loss: 0.01026
[14,    47] Training loss: 0.01072
[14,    48] Training loss: 0.00985
[14,    49] Training loss: 0.01034
[14,    50] Training loss: 0.01043
[14,    51] Training loss: 0.00984
[14,    52] Training loss: 0.01122
[14,    53] Training loss: 0.01092
[14,    54] Training loss: 0.01057
[14,    55] Training loss: 0.01000
[14,    56] Training loss: 0.00994
[14,    57] Training loss: 0.01048
[14] Validation loss: 0.01031
[15,     1] Training loss: 0.00999
[15,     2] Training loss: 0.01006
[15,     3] Training loss: 0.01002
[15,     4] Training loss: 0.00973
[15,     5] Training loss: 0.01004
[15,     6] Training loss: 0.01002
[15,     7] Training loss: 0.01019
[15,     8] Training loss: 0.00978
[15,     9] Training loss: 0.01003
[15,    10] Training loss: 0.01006
[15,    11] Training loss: 0.01017
[15,    12] Training loss: 0.00956
[15,    13] Training loss: 0.00971
[15,    14] Training loss: 0.00995
[15,    15] Training loss: 0.01022
[15,    16] Training loss: 0.01010
[15,    17] Training loss: 0.00995
[15,    18] Training loss: 0.00985
[15,    19] Training loss: 0.01015
[15,    20] Training loss: 0.00979
[15,    21] Training loss: 0.00990
[15,    22] Training loss: 0.00965
[15,    23] Training loss: 0.00954
[15,    24] Training loss: 0.01009
[15,    25] Training loss: 0.00977
[15,    26] Training loss: 0.00977
[15,    27] Training loss: 0.01001
[15,    28] Training loss: 0.00996
[15,    29] Training loss: 0.00987
[15,    30] Training loss: 0.01027
[15,    31] Training loss: 0.00999
[15,    32] Training loss: 0.00956
[15,    33] Training loss: 0.00974
[15,    34] Training loss: 0.00958
[15,    35] Training loss: 0.01002
[15,    36] Training loss: 0.00970
[15,    37] Training loss: 0.00964
[15,    38] Training loss: 0.00933
[15,    39] Training loss: 0.00967
[15,    40] Training loss: 0.00942
[15,    41] Training loss: 0.00985
[15,    42] Training loss: 0.01003
[15,    43] Training loss: 0.00947
[15,    44] Training loss: 0.01031
[15,    45] Training loss: 0.01015
[15,    46] Training loss: 0.00966
[15,    47] Training loss: 0.01017
[15,    48] Training loss: 0.00983
[15,    49] Training loss: 0.01023
[15,    50] Training loss: 0.00949
[15,    51] Training loss: 0.00961
[15,    52] Training loss: 0.01051
[15,    53] Training loss: 0.00989
[15,    54] Training loss: 0.01041
[15,    55] Training loss: 0.00988
[15,    56] Training loss: 0.00979
[15,    57] Training loss: 0.01076
[15] Validation loss: 0.01099
[16,     1] Training loss: 0.01095
[16,     2] Training loss: 0.01045
[16,     3] Training loss: 0.01028
[16,     4] Training loss: 0.01018
[16,     5] Training loss: 0.01016
[16,     6] Training loss: 0.01022
[16,     7] Training loss: 0.01010
[16,     8] Training loss: 0.00954
[16,     9] Training loss: 0.00972
[16,    10] Training loss: 0.00979
[16,    11] Training loss: 0.00989
[16,    12] Training loss: 0.00949
[16,    13] Training loss: 0.00955
[16,    14] Training loss: 0.00938
[16,    15] Training loss: 0.00958
[16,    16] Training loss: 0.00994
[16,    17] Training loss: 0.00969
[16,    18] Training loss: 0.00987
[16,    19] Training loss: 0.01002
[16,    20] Training loss: 0.00975
[16,    21] Training loss: 0.00961
[16,    22] Training loss: 0.00987
[16,    23] Training loss: 0.00951
[16,    24] Training loss: 0.00959
[16,    25] Training loss: 0.00944
[16,    26] Training loss: 0.00959
[16,    27] Training loss: 0.00998
[16,    28] Training loss: 0.01024
[16,    29] Training loss: 0.01033
[16,    30] Training loss: 0.00944
[16,    31] Training loss: 0.01046
[16,    32] Training loss: 0.01091
[16,    33] Training loss: 0.01015
[16,    34] Training loss: 0.01030
[16,    35] Training loss: 0.00987
[16,    36] Training loss: 0.00981
[16,    37] Training loss: 0.01009
[16,    38] Training loss: 0.01005
[16,    39] Training loss: 0.00968
[16,    40] Training loss: 0.00980
[16,    41] Training loss: 0.00959
[16,    42] Training loss: 0.00934
[16,    43] Training loss: 0.00980
[16,    44] Training loss: 0.00935
[16,    45] Training loss: 0.00937
[16,    46] Training loss: 0.00937
[16,    47] Training loss: 0.00942
[16,    48] Training loss: 0.00929
[16,    49] Training loss: 0.00979
[16,    50] Training loss: 0.00967
[16,    51] Training loss: 0.00953
[16,    52] Training loss: 0.00952
[16,    53] Training loss: 0.00975
[16,    54] Training loss: 0.00951
[16,    55] Training loss: 0.00955
[16,    56] Training loss: 0.00930
[16,    57] Training loss: 0.00874
[16] Validation loss: 0.00987
[17,     1] Training loss: 0.00959
[17,     2] Training loss: 0.00942
[17,     3] Training loss: 0.00934
[17,     4] Training loss: 0.00944
[17,     5] Training loss: 0.00985
[17,     6] Training loss: 0.00934
[17,     7] Training loss: 0.00987
[17,     8] Training loss: 0.00921
[17,     9] Training loss: 0.01041
[17,    10] Training loss: 0.01055
[17,    11] Training loss: 0.00958
[17,    12] Training loss: 0.00969
[17,    13] Training loss: 0.00927
[17,    14] Training loss: 0.00955
[17,    15] Training loss: 0.01002
[17,    16] Training loss: 0.00978
[17,    17] Training loss: 0.00928
[17,    18] Training loss: 0.00944
[17,    19] Training loss: 0.00990
[17,    20] Training loss: 0.00956
[17,    21] Training loss: 0.00970
[17,    22] Training loss: 0.00988
[17,    23] Training loss: 0.00984
[17,    24] Training loss: 0.00985
[17,    25] Training loss: 0.00980
[17,    26] Training loss: 0.00976
[17,    27] Training loss: 0.00916
[17,    28] Training loss: 0.00924
[17,    29] Training loss: 0.00932
[17,    30] Training loss: 0.00951
[17,    31] Training loss: 0.00961
[17,    32] Training loss: 0.00931
[17,    33] Training loss: 0.00888
[17,    34] Training loss: 0.00903
[17,    35] Training loss: 0.00956
[17,    36] Training loss: 0.00955
[17,    37] Training loss: 0.00930
[17,    38] Training loss: 0.00936
[17,    39] Training loss: 0.00916
[17,    40] Training loss: 0.00920
[17,    41] Training loss: 0.00920
[17,    42] Training loss: 0.00944
[17,    43] Training loss: 0.00935
[17,    44] Training loss: 0.00963
[17,    45] Training loss: 0.00968
[17,    46] Training loss: 0.00897
[17,    47] Training loss: 0.00931
[17,    48] Training loss: 0.00947
[17,    49] Training loss: 0.00991
[17,    50] Training loss: 0.00959
[17,    51] Training loss: 0.00942
[17,    52] Training loss: 0.00936
[17,    53] Training loss: 0.00921
[17,    54] Training loss: 0.00962
[17,    55] Training loss: 0.00942
[17,    56] Training loss: 0.00935
[17,    57] Training loss: 0.00903
[17] Validation loss: 0.00955
[18,     1] Training loss: 0.00928
[18,     2] Training loss: 0.00966
[18,     3] Training loss: 0.00944
[18,     4] Training loss: 0.00907
[18,     5] Training loss: 0.00986
[18,     6] Training loss: 0.01076
[18,     7] Training loss: 0.01036
[18,     8] Training loss: 0.00938
[18,     9] Training loss: 0.00926
[18,    10] Training loss: 0.00924
[18,    11] Training loss: 0.00944
[18,    12] Training loss: 0.00931
[18,    13] Training loss: 0.00936
[18,    14] Training loss: 0.00924
[18,    15] Training loss: 0.00917
[18,    16] Training loss: 0.00920
[18,    17] Training loss: 0.00905
[18,    18] Training loss: 0.00907
[18,    19] Training loss: 0.00975
[18,    20] Training loss: 0.00903
[18,    21] Training loss: 0.00893
[18,    22] Training loss: 0.00909
[18,    23] Training loss: 0.00903
[18,    24] Training loss: 0.00936
[18,    25] Training loss: 0.00961
[18,    26] Training loss: 0.00943
[18,    27] Training loss: 0.00920
[18,    28] Training loss: 0.00942
[18,    29] Training loss: 0.00941
[18,    30] Training loss: 0.00911
[18,    31] Training loss: 0.00913
[18,    32] Training loss: 0.00922
[18,    33] Training loss: 0.00920
[18,    34] Training loss: 0.00911
[18,    35] Training loss: 0.00899
[18,    36] Training loss: 0.00905
[18,    37] Training loss: 0.00909
[18,    38] Training loss: 0.00924
[18,    39] Training loss: 0.00884
[18,    40] Training loss: 0.00903
[18,    41] Training loss: 0.00907
[18,    42] Training loss: 0.00949
[18,    43] Training loss: 0.00938
[18,    44] Training loss: 0.00885
[18,    45] Training loss: 0.00908
[18,    46] Training loss: 0.00903
[18,    47] Training loss: 0.00873
[18,    48] Training loss: 0.00919
[18,    49] Training loss: 0.00936
[18,    50] Training loss: 0.00904
[18,    51] Training loss: 0.00929
[18,    52] Training loss: 0.00947
[18,    53] Training loss: 0.00885
[18,    54] Training loss: 0.00902
[18,    55] Training loss: 0.00929
[18,    56] Training loss: 0.01010
[18,    57] Training loss: 0.00974
[18] Validation loss: 0.01004
[19,     1] Training loss: 0.00932
[19,     2] Training loss: 0.00895
[19,     3] Training loss: 0.00920
[19,     4] Training loss: 0.00898
[19,     5] Training loss: 0.00920
[19,     6] Training loss: 0.00897
[19,     7] Training loss: 0.00901
[19,     8] Training loss: 0.00893
[19,     9] Training loss: 0.00902
[19,    10] Training loss: 0.00904
[19,    11] Training loss: 0.00906
[19,    12] Training loss: 0.00922
[19,    13] Training loss: 0.00879
[19,    14] Training loss: 0.00894
[19,    15] Training loss: 0.00897
[19,    16] Training loss: 0.00923
[19,    17] Training loss: 0.00896
[19,    18] Training loss: 0.00877
[19,    19] Training loss: 0.00881
[19,    20] Training loss: 0.00918
[19,    21] Training loss: 0.00888
[19,    22] Training loss: 0.00908
[19,    23] Training loss: 0.00910
[19,    24] Training loss: 0.00874
[19,    25] Training loss: 0.00874
[19,    26] Training loss: 0.00860
[19,    27] Training loss: 0.00886
[19,    28] Training loss: 0.00888
[19,    29] Training loss: 0.00924
[19,    30] Training loss: 0.00936
[19,    31] Training loss: 0.00905
[19,    32] Training loss: 0.00861
[19,    33] Training loss: 0.00922
[19,    34] Training loss: 0.00909
[19,    35] Training loss: 0.00905
[19,    36] Training loss: 0.00882
[19,    37] Training loss: 0.00880
[19,    38] Training loss: 0.00895
[19,    39] Training loss: 0.00836
[19,    40] Training loss: 0.00899
[19,    41] Training loss: 0.00897
[19,    42] Training loss: 0.00877
[19,    43] Training loss: 0.00864
[19,    44] Training loss: 0.00864
[19,    45] Training loss: 0.00940
[19,    46] Training loss: 0.00895
[19,    47] Training loss: 0.00994
[19,    48] Training loss: 0.00912
[19,    49] Training loss: 0.00898
[19,    50] Training loss: 0.00901
[19,    51] Training loss: 0.00903
[19,    52] Training loss: 0.00917
[19,    53] Training loss: 0.00916
[19,    54] Training loss: 0.00894
[19,    55] Training loss: 0.00918
[19,    56] Training loss: 0.00947
[19,    57] Training loss: 0.00944
[19] Validation loss: 0.01011
[20,     1] Training loss: 0.00910
[20,     2] Training loss: 0.00985
[20,     3] Training loss: 0.01038
[20,     4] Training loss: 0.01022
[20,     5] Training loss: 0.00961
[20,     6] Training loss: 0.00924
[20,     7] Training loss: 0.00906
[20,     8] Training loss: 0.00920
[20,     9] Training loss: 0.00910
[20,    10] Training loss: 0.00906
[20,    11] Training loss: 0.00914
[20,    12] Training loss: 0.00904
[20,    13] Training loss: 0.00919
[20,    14] Training loss: 0.00861
[20,    15] Training loss: 0.00902
[20,    16] Training loss: 0.00913
[20,    17] Training loss: 0.00841
[20,    18] Training loss: 0.00885
[20,    19] Training loss: 0.00913
[20,    20] Training loss: 0.00868
[20,    21] Training loss: 0.00871
[20,    22] Training loss: 0.00824
[20,    23] Training loss: 0.00864
[20,    24] Training loss: 0.00937
[20,    25] Training loss: 0.00870
[20,    26] Training loss: 0.00892
[20,    27] Training loss: 0.00872
[20,    28] Training loss: 0.00902
[20,    29] Training loss: 0.00914
[20,    30] Training loss: 0.00893
[20,    31] Training loss: 0.00870
[20,    32] Training loss: 0.00858
[20,    33] Training loss: 0.00856
[20,    34] Training loss: 0.00863
[20,    35] Training loss: 0.00872
[20,    36] Training loss: 0.00835
[20,    37] Training loss: 0.00851
[20,    38] Training loss: 0.00855
[20,    39] Training loss: 0.00857
[20,    40] Training loss: 0.00862
[20,    41] Training loss: 0.00886
[20,    42] Training loss: 0.00873
[20,    43] Training loss: 0.00834
[20,    44] Training loss: 0.00858
[20,    45] Training loss: 0.00914
[20,    46] Training loss: 0.00883
[20,    47] Training loss: 0.00826
[20,    48] Training loss: 0.00872
[20,    49] Training loss: 0.00886
[20,    50] Training loss: 0.00860
[20,    51] Training loss: 0.00860
[20,    52] Training loss: 0.00827
[20,    53] Training loss: 0.00844
[20,    54] Training loss: 0.00861
[20,    55] Training loss: 0.00876
[20,    56] Training loss: 0.00856
[20,    57] Training loss: 0.00935
[20] Validation loss: 0.00908
[21,     1] Training loss: 0.00878
[21,     2] Training loss: 0.00873
[21,     3] Training loss: 0.00905
[21,     4] Training loss: 0.00910
[21,     5] Training loss: 0.00894
[21,     6] Training loss: 0.00911
[21,     7] Training loss: 0.00927
[21,     8] Training loss: 0.00888
[21,     9] Training loss: 0.00889
[21,    10] Training loss: 0.00872
[21,    11] Training loss: 0.00911
[21,    12] Training loss: 0.00852
[21,    13] Training loss: 0.00873
[21,    14] Training loss: 0.00902
[21,    15] Training loss: 0.00875
[21,    16] Training loss: 0.00859
[21,    17] Training loss: 0.00867
[21,    18] Training loss: 0.00887
[21,    19] Training loss: 0.00873
[21,    20] Training loss: 0.00904
[21,    21] Training loss: 0.00913
[21,    22] Training loss: 0.00881
[21,    23] Training loss: 0.00867
[21,    24] Training loss: 0.00865
[21,    25] Training loss: 0.00893
[21,    26] Training loss: 0.00854
[21,    27] Training loss: 0.00836
[21,    28] Training loss: 0.00839
[21,    29] Training loss: 0.00866
[21,    30] Training loss: 0.00818
[21,    31] Training loss: 0.00884
[21,    32] Training loss: 0.00839
[21,    33] Training loss: 0.00882
[21,    34] Training loss: 0.00924
[21,    35] Training loss: 0.00845
[21,    36] Training loss: 0.00837
[21,    37] Training loss: 0.00879
[21,    38] Training loss: 0.00852
[21,    39] Training loss: 0.00880
[21,    40] Training loss: 0.00906
[21,    41] Training loss: 0.00883
[21,    42] Training loss: 0.00872
[21,    43] Training loss: 0.00876
[21,    44] Training loss: 0.00889
[21,    45] Training loss: 0.00915
[21,    46] Training loss: 0.00899
[21,    47] Training loss: 0.00862
[21,    48] Training loss: 0.00880
[21,    49] Training loss: 0.00847
[21,    50] Training loss: 0.00893
[21,    51] Training loss: 0.00885
[21,    52] Training loss: 0.00843
[21,    53] Training loss: 0.00867
[21,    54] Training loss: 0.00857
[21,    55] Training loss: 0.00874
[21,    56] Training loss: 0.00859
[21,    57] Training loss: 0.00850
[21] Validation loss: 0.01074
[22,     1] Training loss: 0.01041
[22,     2] Training loss: 0.00915
[22,     3] Training loss: 0.00941
[22,     4] Training loss: 0.01030
[22,     5] Training loss: 0.00944
[22,     6] Training loss: 0.00907
[22,     7] Training loss: 0.00903
[22,     8] Training loss: 0.00903
[22,     9] Training loss: 0.00909
[22,    10] Training loss: 0.00883
[22,    11] Training loss: 0.00867
[22,    12] Training loss: 0.00878
[22,    13] Training loss: 0.00849
[22,    14] Training loss: 0.00904
[22,    15] Training loss: 0.00960
[22,    16] Training loss: 0.00913
[22,    17] Training loss: 0.00911
[22,    18] Training loss: 0.00926
[22,    19] Training loss: 0.00877
[22,    20] Training loss: 0.00883
[22,    21] Training loss: 0.00882
[22,    22] Training loss: 0.00862
[22,    23] Training loss: 0.00874
[22,    24] Training loss: 0.00859
[22,    25] Training loss: 0.00863
[22,    26] Training loss: 0.00865
[22,    27] Training loss: 0.00854
[22,    28] Training loss: 0.00845
[22,    29] Training loss: 0.00879
[22,    30] Training loss: 0.00868
[22,    31] Training loss: 0.00839
[22,    32] Training loss: 0.00864
[22,    33] Training loss: 0.00870
[22,    34] Training loss: 0.00799
[22,    35] Training loss: 0.00873
[22,    36] Training loss: 0.00919
[22,    37] Training loss: 0.00842
[22,    38] Training loss: 0.00888
[22,    39] Training loss: 0.00871
[22,    40] Training loss: 0.00832
[22,    41] Training loss: 0.00896
[22,    42] Training loss: 0.00853
[22,    43] Training loss: 0.00877
[22,    44] Training loss: 0.00855
[22,    45] Training loss: 0.00841
[22,    46] Training loss: 0.00856
[22,    47] Training loss: 0.00886
[22,    48] Training loss: 0.00858
[22,    49] Training loss: 0.00859
[22,    50] Training loss: 0.00850
[22,    51] Training loss: 0.00837
[22,    52] Training loss: 0.00839
[22,    53] Training loss: 0.00781
[22,    54] Training loss: 0.00843
[22,    55] Training loss: 0.00854
[22,    56] Training loss: 0.00826
[22,    57] Training loss: 0.00891
[22] Validation loss: 0.00862
[23,     1] Training loss: 0.00827
[23,     2] Training loss: 0.00814
[23,     3] Training loss: 0.00864
[23,     4] Training loss: 0.00853
[23,     5] Training loss: 0.00801
[23,     6] Training loss: 0.00818
[23,     7] Training loss: 0.00849
[23,     8] Training loss: 0.00843
[23,     9] Training loss: 0.00843
[23,    10] Training loss: 0.00829
[23,    11] Training loss: 0.00839
[23,    12] Training loss: 0.00806
[23,    13] Training loss: 0.00890
[23,    14] Training loss: 0.00900
[23,    15] Training loss: 0.00835
[23,    16] Training loss: 0.00974
[23,    17] Training loss: 0.00899
[23,    18] Training loss: 0.00841
[23,    19] Training loss: 0.00911
[23,    20] Training loss: 0.00886
[23,    21] Training loss: 0.00857
[23,    22] Training loss: 0.00815
[23,    23] Training loss: 0.00889
[23,    24] Training loss: 0.00917
[23,    25] Training loss: 0.00882
[23,    26] Training loss: 0.00886
[23,    27] Training loss: 0.00865
[23,    28] Training loss: 0.00876
[23,    29] Training loss: 0.00830
[23,    30] Training loss: 0.00854
[23,    31] Training loss: 0.00826
[23,    32] Training loss: 0.00852
[23,    33] Training loss: 0.00835
[23,    34] Training loss: 0.00823
[23,    35] Training loss: 0.00856
[23,    36] Training loss: 0.00842
[23,    37] Training loss: 0.00803
[23,    38] Training loss: 0.00791
[23,    39] Training loss: 0.00802
[23,    40] Training loss: 0.00861
[23,    41] Training loss: 0.00877
[23,    42] Training loss: 0.00822
[23,    43] Training loss: 0.00892
[23,    44] Training loss: 0.00817
[23,    45] Training loss: 0.00891
[23,    46] Training loss: 0.00872
[23,    47] Training loss: 0.00867
[23,    48] Training loss: 0.00859
[23,    49] Training loss: 0.00837
[23,    50] Training loss: 0.00879
[23,    51] Training loss: 0.00845
[23,    52] Training loss: 0.00811
[23,    53] Training loss: 0.00852
[23,    54] Training loss: 0.00835
[23,    55] Training loss: 0.00816
[23,    56] Training loss: 0.00880
[23,    57] Training loss: 0.00795
[23] Validation loss: 0.00891
[24,     1] Training loss: 0.00814
[24,     2] Training loss: 0.00860
[24,     3] Training loss: 0.00823
[24,     4] Training loss: 0.00837
[24,     5] Training loss: 0.00817
[24,     6] Training loss: 0.00857
[24,     7] Training loss: 0.00848
[24,     8] Training loss: 0.00865
[24,     9] Training loss: 0.00849
[24,    10] Training loss: 0.00826
[24,    11] Training loss: 0.00807
[24,    12] Training loss: 0.00838
[24,    13] Training loss: 0.00811
[24,    14] Training loss: 0.00797
[24,    15] Training loss: 0.00837
[24,    16] Training loss: 0.00809
[24,    17] Training loss: 0.00810
[24,    18] Training loss: 0.00795
[24,    19] Training loss: 0.00837
[24,    20] Training loss: 0.00805
[24,    21] Training loss: 0.00820
[24,    22] Training loss: 0.00803
[24,    23] Training loss: 0.00841
[24,    24] Training loss: 0.00806
[24,    25] Training loss: 0.00790
[24,    26] Training loss: 0.00811
[24,    27] Training loss: 0.00803
[24,    28] Training loss: 0.00797
[24,    29] Training loss: 0.00826
[24,    30] Training loss: 0.00795
[24,    31] Training loss: 0.00805
[24,    32] Training loss: 0.00811
[24,    33] Training loss: 0.00818
[24,    34] Training loss: 0.00808
[24,    35] Training loss: 0.00825
[24,    36] Training loss: 0.00802
[24,    37] Training loss: 0.00817
[24,    38] Training loss: 0.00788
[24,    39] Training loss: 0.00773
[24,    40] Training loss: 0.00804
[24,    41] Training loss: 0.00780
[24,    42] Training loss: 0.00818
[24,    43] Training loss: 0.00813
[24,    44] Training loss: 0.00826
[24,    45] Training loss: 0.00874
[24,    46] Training loss: 0.00826
[24,    47] Training loss: 0.00803
[24,    48] Training loss: 0.00835
[24,    49] Training loss: 0.00858
[24,    50] Training loss: 0.00830
[24,    51] Training loss: 0.00854
[24,    52] Training loss: 0.00857
[24,    53] Training loss: 0.00832
[24,    54] Training loss: 0.00821
[24,    55] Training loss: 0.00856
[24,    56] Training loss: 0.00840
[24,    57] Training loss: 0.00761
[24] Validation loss: 0.00882
[25,     1] Training loss: 0.00830
[25,     2] Training loss: 0.00838
[25,     3] Training loss: 0.00797
[25,     4] Training loss: 0.00800
[25,     5] Training loss: 0.00861
[25,     6] Training loss: 0.00798
[25,     7] Training loss: 0.00802
[25,     8] Training loss: 0.00791
[25,     9] Training loss: 0.00826
[25,    10] Training loss: 0.00819
[25,    11] Training loss: 0.00798
[25,    12] Training loss: 0.00793
[25,    13] Training loss: 0.00816
[25,    14] Training loss: 0.00784
[25,    15] Training loss: 0.00790
[25,    16] Training loss: 0.00831
[25,    17] Training loss: 0.00799
[25,    18] Training loss: 0.00869
[25,    19] Training loss: 0.00796
[25,    20] Training loss: 0.00897
[25,    21] Training loss: 0.00837
[25,    22] Training loss: 0.00819
[25,    23] Training loss: 0.00843
[25,    24] Training loss: 0.00817
[25,    25] Training loss: 0.00859
[25,    26] Training loss: 0.00878
[25,    27] Training loss: 0.00831
[25,    28] Training loss: 0.00835
[25,    29] Training loss: 0.00822
[25,    30] Training loss: 0.00861
[25,    31] Training loss: 0.00890
[25,    32] Training loss: 0.00812
[25,    33] Training loss: 0.00821
[25,    34] Training loss: 0.00845
[25,    35] Training loss: 0.00798
[25,    36] Training loss: 0.00848
[25,    37] Training loss: 0.00795
[25,    38] Training loss: 0.00787
[25,    39] Training loss: 0.00827
[25,    40] Training loss: 0.00811
[25,    41] Training loss: 0.00768
[25,    42] Training loss: 0.00829
[25,    43] Training loss: 0.00801
[25,    44] Training loss: 0.00816
[25,    45] Training loss: 0.00792
[25,    46] Training loss: 0.00787
[25,    47] Training loss: 0.00803
[25,    48] Training loss: 0.00793
[25,    49] Training loss: 0.00798
[25,    50] Training loss: 0.00817
[25,    51] Training loss: 0.00859
[25,    52] Training loss: 0.00809
[25,    53] Training loss: 0.00791
[25,    54] Training loss: 0.00853
[25,    55] Training loss: 0.00827
[25,    56] Training loss: 0.00810
[25,    57] Training loss: 0.00996
[25] Validation loss: 0.00969
[26,     1] Training loss: 0.00914
[26,     2] Training loss: 0.00858
[26,     3] Training loss: 0.00886
[26,     4] Training loss: 0.00854
[26,     5] Training loss: 0.00867
[26,     6] Training loss: 0.00854
[26,     7] Training loss: 0.00850
[26,     8] Training loss: 0.00845
[26,     9] Training loss: 0.00838
[26,    10] Training loss: 0.00814
[26,    11] Training loss: 0.00844
[26,    12] Training loss: 0.00783
[26,    13] Training loss: 0.00836
[26,    14] Training loss: 0.00829
[26,    15] Training loss: 0.00790
[26,    16] Training loss: 0.00799
[26,    17] Training loss: 0.00825
[26,    18] Training loss: 0.00798
[26,    19] Training loss: 0.00766
[26,    20] Training loss: 0.00772
[26,    21] Training loss: 0.00817
[26,    22] Training loss: 0.00787
[26,    23] Training loss: 0.00789
[26,    24] Training loss: 0.00773
[26,    25] Training loss: 0.00812
[26,    26] Training loss: 0.00791
[26,    27] Training loss: 0.00743
[26,    28] Training loss: 0.00788
[26,    29] Training loss: 0.00760
[26,    30] Training loss: 0.00800
[26,    31] Training loss: 0.00806
[26,    32] Training loss: 0.00812
[26,    33] Training loss: 0.00788
[26,    34] Training loss: 0.00772
[26,    35] Training loss: 0.00808
[26,    36] Training loss: 0.00834
[26,    37] Training loss: 0.00757
[26,    38] Training loss: 0.00773
[26,    39] Training loss: 0.00773
[26,    40] Training loss: 0.00771
[26,    41] Training loss: 0.00808
[26,    42] Training loss: 0.00787
[26,    43] Training loss: 0.00820
[26,    44] Training loss: 0.00804
[26,    45] Training loss: 0.00747
[26,    46] Training loss: 0.00812
[26,    47] Training loss: 0.00806
[26,    48] Training loss: 0.00767
[26,    49] Training loss: 0.00776
[26,    50] Training loss: 0.00828
[26,    51] Training loss: 0.00798
[26,    52] Training loss: 0.00809
[26,    53] Training loss: 0.00795
[26,    54] Training loss: 0.00856
[26,    55] Training loss: 0.00776
[26,    56] Training loss: 0.00778
[26,    57] Training loss: 0.00841
[26] Validation loss: 0.00880
[27,     1] Training loss: 0.00844
[27,     2] Training loss: 0.00765
[27,     3] Training loss: 0.00907
[27,     4] Training loss: 0.00873
[27,     5] Training loss: 0.00832
[27,     6] Training loss: 0.00829
[27,     7] Training loss: 0.00767
[27,     8] Training loss: 0.00829
[27,     9] Training loss: 0.00812
[27,    10] Training loss: 0.00806
[27,    11] Training loss: 0.00807
[27,    12] Training loss: 0.00783
[27,    13] Training loss: 0.00782
[27,    14] Training loss: 0.00796
[27,    15] Training loss: 0.00787
[27,    16] Training loss: 0.00799
[27,    17] Training loss: 0.00778
[27,    18] Training loss: 0.00773
[27,    19] Training loss: 0.00792
[27,    20] Training loss: 0.00790
[27,    21] Training loss: 0.00780
[27,    22] Training loss: 0.00811
[27,    23] Training loss: 0.00760
[27,    24] Training loss: 0.00808
[27,    25] Training loss: 0.00778
[27,    26] Training loss: 0.00750
[27,    27] Training loss: 0.00803
[27,    28] Training loss: 0.00763
[27,    29] Training loss: 0.00768
[27,    30] Training loss: 0.00759
[27,    31] Training loss: 0.00761
[27,    32] Training loss: 0.00780
[27,    33] Training loss: 0.00774
[27,    34] Training loss: 0.00747
[27,    35] Training loss: 0.00747
[27,    36] Training loss: 0.00726
[27,    37] Training loss: 0.00760
[27,    38] Training loss: 0.00760
[27,    39] Training loss: 0.00785
[27,    40] Training loss: 0.00752
[27,    41] Training loss: 0.00747
[27,    42] Training loss: 0.00750
[27,    43] Training loss: 0.00740
[27,    44] Training loss: 0.00743
[27,    45] Training loss: 0.00770
[27,    46] Training loss: 0.00751
[27,    47] Training loss: 0.00805
[27,    48] Training loss: 0.00784
[27,    49] Training loss: 0.00761
[27,    50] Training loss: 0.00767
[27,    51] Training loss: 0.00787
[27,    52] Training loss: 0.00738
[27,    53] Training loss: 0.00780
[27,    54] Training loss: 0.00800
[27,    55] Training loss: 0.00807
[27,    56] Training loss: 0.00762
[27,    57] Training loss: 0.00829
[27] Validation loss: 0.00808
[28,     1] Training loss: 0.00769
[28,     2] Training loss: 0.00799
[28,     3] Training loss: 0.00749
[28,     4] Training loss: 0.00783
[28,     5] Training loss: 0.00777
[28,     6] Training loss: 0.00809
[28,     7] Training loss: 0.00760
[28,     8] Training loss: 0.00843
[28,     9] Training loss: 0.00777
[28,    10] Training loss: 0.00810
[28,    11] Training loss: 0.00862
[28,    12] Training loss: 0.00791
[28,    13] Training loss: 0.00773
[28,    14] Training loss: 0.00793
[28,    15] Training loss: 0.00768
[28,    16] Training loss: 0.00760
[28,    17] Training loss: 0.00759
[28,    18] Training loss: 0.00829
[28,    19] Training loss: 0.00808
[28,    20] Training loss: 0.00833
[28,    21] Training loss: 0.00810
[28,    22] Training loss: 0.00847
[28,    23] Training loss: 0.00801
[28,    24] Training loss: 0.00782
[28,    25] Training loss: 0.00765
[28,    26] Training loss: 0.00799
[28,    27] Training loss: 0.00774
[28,    28] Training loss: 0.00793
[28,    29] Training loss: 0.00778
[28,    30] Training loss: 0.00811
[28,    31] Training loss: 0.00764
[28,    32] Training loss: 0.00781
[28,    33] Training loss: 0.00786
[28,    34] Training loss: 0.00762
[28,    35] Training loss: 0.00754
[28,    36] Training loss: 0.00755
[28,    37] Training loss: 0.00755
[28,    38] Training loss: 0.00754
[28,    39] Training loss: 0.00731
[28,    40] Training loss: 0.00756
[28,    41] Training loss: 0.00766
[28,    42] Training loss: 0.00751
[28,    43] Training loss: 0.00762
[28,    44] Training loss: 0.00768
[28,    45] Training loss: 0.00744
[28,    46] Training loss: 0.00735
[28,    47] Training loss: 0.00735
[28,    48] Training loss: 0.00805
[28,    49] Training loss: 0.00780
[28,    50] Training loss: 0.00764
[28,    51] Training loss: 0.00733
[28,    52] Training loss: 0.00746
[28,    53] Training loss: 0.00780
[28,    54] Training loss: 0.00760
[28,    55] Training loss: 0.00723
[28,    56] Training loss: 0.00745
[28,    57] Training loss: 0.00772
[28] Validation loss: 0.00791
[29,     1] Training loss: 0.00763
[29,     2] Training loss: 0.00744
[29,     3] Training loss: 0.00770
[29,     4] Training loss: 0.00796
[29,     5] Training loss: 0.00776
[29,     6] Training loss: 0.00770
[29,     7] Training loss: 0.00774
[29,     8] Training loss: 0.00772
[29,     9] Training loss: 0.00803
[29,    10] Training loss: 0.00790
[29,    11] Training loss: 0.00753
[29,    12] Training loss: 0.00764
[29,    13] Training loss: 0.00799
[29,    14] Training loss: 0.00779
[29,    15] Training loss: 0.00792
[29,    16] Training loss: 0.00769
[29,    17] Training loss: 0.00778
[29,    18] Training loss: 0.00742
[29,    19] Training loss: 0.00759
[29,    20] Training loss: 0.00807
[29,    21] Training loss: 0.00764
[29,    22] Training loss: 0.00783
[29,    23] Training loss: 0.00745
[29,    24] Training loss: 0.00738
[29,    25] Training loss: 0.00762
[29,    26] Training loss: 0.00767
[29,    27] Training loss: 0.00741
[29,    28] Training loss: 0.00753
[29,    29] Training loss: 0.00783
[29,    30] Training loss: 0.00716
[29,    31] Training loss: 0.00729
[29,    32] Training loss: 0.00750
[29,    33] Training loss: 0.00745
[29,    34] Training loss: 0.00711
[29,    35] Training loss: 0.00723
[29,    36] Training loss: 0.00768
[29,    37] Training loss: 0.00719
[29,    38] Training loss: 0.00767
[29,    39] Training loss: 0.00760
[29,    40] Training loss: 0.00739
[29,    41] Training loss: 0.00764
[29,    42] Training loss: 0.00721
[29,    43] Training loss: 0.00738
[29,    44] Training loss: 0.00736
[29,    45] Training loss: 0.00754
[29,    46] Training loss: 0.00744
[29,    47] Training loss: 0.00763
[29,    48] Training loss: 0.00737
[29,    49] Training loss: 0.00727
[29,    50] Training loss: 0.00715
[29,    51] Training loss: 0.00749
[29,    52] Training loss: 0.00764
[29,    53] Training loss: 0.00756
[29,    54] Training loss: 0.00740
[29,    55] Training loss: 0.00745
[29,    56] Training loss: 0.00777
[29,    57] Training loss: 0.00780
[29] Validation loss: 0.00771
[30,     1] Training loss: 0.00720
[30,     2] Training loss: 0.00716
[30,     3] Training loss: 0.00748
[30,     4] Training loss: 0.00731
[30,     5] Training loss: 0.00748
[30,     6] Training loss: 0.00751
[30,     7] Training loss: 0.00717
[30,     8] Training loss: 0.00732
[30,     9] Training loss: 0.00741
[30,    10] Training loss: 0.00787
[30,    11] Training loss: 0.00777
[30,    12] Training loss: 0.00750
[30,    13] Training loss: 0.00778
[30,    14] Training loss: 0.00751
[30,    15] Training loss: 0.00749
[30,    16] Training loss: 0.00740
[30,    17] Training loss: 0.00739
[30,    18] Training loss: 0.00742
[30,    19] Training loss: 0.00768
[30,    20] Training loss: 0.00775
[30,    21] Training loss: 0.00753
[30,    22] Training loss: 0.00775
[30,    23] Training loss: 0.00756
[30,    24] Training loss: 0.00765
[30,    25] Training loss: 0.00755
[30,    26] Training loss: 0.00786
[30,    27] Training loss: 0.00744
[30,    28] Training loss: 0.00746
[30,    29] Training loss: 0.00746
[30,    30] Training loss: 0.00769
[30,    31] Training loss: 0.00709
[30,    32] Training loss: 0.00744
[30,    33] Training loss: 0.00758
[30,    34] Training loss: 0.00763
[30,    35] Training loss: 0.00793
[30,    36] Training loss: 0.00732
[30,    37] Training loss: 0.00731
[30,    38] Training loss: 0.00765
[30,    39] Training loss: 0.00745
[30,    40] Training loss: 0.00746
[30,    41] Training loss: 0.00755
[30,    42] Training loss: 0.00728
[30,    43] Training loss: 0.00768
[30,    44] Training loss: 0.00738
[30,    45] Training loss: 0.00719
[30,    46] Training loss: 0.00777
[30,    47] Training loss: 0.00792
[30,    48] Training loss: 0.00738
[30,    49] Training loss: 0.00784
[30,    50] Training loss: 0.00743
[30,    51] Training loss: 0.00775
[30,    52] Training loss: 0.00736
[30,    53] Training loss: 0.00760
[30,    54] Training loss: 0.00748
[30,    55] Training loss: 0.00786
[30,    56] Training loss: 0.00747
[30,    57] Training loss: 0.00791
[30] Validation loss: 0.00808
[31,     1] Training loss: 0.00768
[31,     2] Training loss: 0.00773
[31,     3] Training loss: 0.00814
[31,     4] Training loss: 0.00741
[31,     5] Training loss: 0.00767
[31,     6] Training loss: 0.00754
[31,     7] Training loss: 0.00739
[31,     8] Training loss: 0.00795
[31,     9] Training loss: 0.00727
[31,    10] Training loss: 0.00728
[31,    11] Training loss: 0.00696
[31,    12] Training loss: 0.00706
[31,    13] Training loss: 0.00753
[31,    14] Training loss: 0.00722
[31,    15] Training loss: 0.00745
[31,    16] Training loss: 0.00750
[31,    17] Training loss: 0.00739
[31,    18] Training loss: 0.00740
[31,    19] Training loss: 0.00744
[31,    20] Training loss: 0.00746
[31,    21] Training loss: 0.00743
[31,    22] Training loss: 0.00743
[31,    23] Training loss: 0.00739
[31,    24] Training loss: 0.00718
[31,    25] Training loss: 0.00718
[31,    26] Training loss: 0.00742
[31,    27] Training loss: 0.00738
[31,    28] Training loss: 0.00731
[31,    29] Training loss: 0.00738
[31,    30] Training loss: 0.00773
[31,    31] Training loss: 0.00741
[31,    32] Training loss: 0.00718
[31,    33] Training loss: 0.00813
[31,    34] Training loss: 0.00762
[31,    35] Training loss: 0.00767
[31,    36] Training loss: 0.00720
[31,    37] Training loss: 0.00768
[31,    38] Training loss: 0.00798
[31,    39] Training loss: 0.00774
[31,    40] Training loss: 0.00797
[31,    41] Training loss: 0.00752
[31,    42] Training loss: 0.00709
[31,    43] Training loss: 0.00728
[31,    44] Training loss: 0.00720
[31,    45] Training loss: 0.00758
[31,    46] Training loss: 0.00758
[31,    47] Training loss: 0.00718
[31,    48] Training loss: 0.00709
[31,    49] Training loss: 0.00745
[31,    50] Training loss: 0.00752
[31,    51] Training loss: 0.00747
[31,    52] Training loss: 0.00730
[31,    53] Training loss: 0.00731
[31,    54] Training loss: 0.00750
[31,    55] Training loss: 0.00758
[31,    56] Training loss: 0.00771
[31,    57] Training loss: 0.00782
[31] Validation loss: 0.00850
[32,     1] Training loss: 0.00811
[32,     2] Training loss: 0.00862
[32,     3] Training loss: 0.00783
[32,     4] Training loss: 0.00784
[32,     5] Training loss: 0.00811
[32,     6] Training loss: 0.00766
[32,     7] Training loss: 0.00759
[32,     8] Training loss: 0.00760
[32,     9] Training loss: 0.00749
[32,    10] Training loss: 0.00733
[32,    11] Training loss: 0.00719
[32,    12] Training loss: 0.00752
[32,    13] Training loss: 0.00716
[32,    14] Training loss: 0.00723
[32,    15] Training loss: 0.00703
[32,    16] Training loss: 0.00701
[32,    17] Training loss: 0.00707
[32,    18] Training loss: 0.00721
[32,    19] Training loss: 0.00728
[32,    20] Training loss: 0.00726
[32,    21] Training loss: 0.00764
[32,    22] Training loss: 0.00706
[32,    23] Training loss: 0.00709
[32,    24] Training loss: 0.00738
[32,    25] Training loss: 0.00697
[32,    26] Training loss: 0.00715
[32,    27] Training loss: 0.00745
[32,    28] Training loss: 0.00741
[32,    29] Training loss: 0.00724
[32,    30] Training loss: 0.00755
[32,    31] Training loss: 0.00735
[32,    32] Training loss: 0.00712
[32,    33] Training loss: 0.00745
[32,    34] Training loss: 0.00691
[32,    35] Training loss: 0.00747
[32,    36] Training loss: 0.00718
[32,    37] Training loss: 0.00733
[32,    38] Training loss: 0.00730
[32,    39] Training loss: 0.00717
[32,    40] Training loss: 0.00712
[32,    41] Training loss: 0.00726
[32,    42] Training loss: 0.00728
[32,    43] Training loss: 0.00729
[32,    44] Training loss: 0.00717
[32,    45] Training loss: 0.00746
[32,    46] Training loss: 0.00714
[32,    47] Training loss: 0.00722
[32,    48] Training loss: 0.00741
[32,    49] Training loss: 0.00707
[32,    50] Training loss: 0.00715
[32,    51] Training loss: 0.00728
[32,    52] Training loss: 0.00744
[32,    53] Training loss: 0.00716
[32,    54] Training loss: 0.00705
[32,    55] Training loss: 0.00686
[32,    56] Training loss: 0.00726
[32,    57] Training loss: 0.00802
[32] Validation loss: 0.00787
[33,     1] Training loss: 0.00725
[33,     2] Training loss: 0.00721
[33,     3] Training loss: 0.00731
[33,     4] Training loss: 0.00729
[33,     5] Training loss: 0.00765
[33,     6] Training loss: 0.00749
[33,     7] Training loss: 0.00727
[33,     8] Training loss: 0.00723
[33,     9] Training loss: 0.00733
[33,    10] Training loss: 0.00747
[33,    11] Training loss: 0.00714
[33,    12] Training loss: 0.00749
[33,    13] Training loss: 0.00689
[33,    14] Training loss: 0.00697
[33,    15] Training loss: 0.00714
[33,    16] Training loss: 0.00712
[33,    17] Training loss: 0.00731
[33,    18] Training loss: 0.00720
[33,    19] Training loss: 0.00753
[33,    20] Training loss: 0.00709
[33,    21] Training loss: 0.00730
[33,    22] Training loss: 0.00696
[33,    23] Training loss: 0.00725
[33,    24] Training loss: 0.00720
[33,    25] Training loss: 0.00698
[33,    26] Training loss: 0.00737
[33,    27] Training loss: 0.00709
[33,    28] Training loss: 0.00707
[33,    29] Training loss: 0.00725
[33,    30] Training loss: 0.00714
[33,    31] Training loss: 0.00720
[33,    32] Training loss: 0.00692
[33,    33] Training loss: 0.00704
[33,    34] Training loss: 0.00706
[33,    35] Training loss: 0.00712
[33,    36] Training loss: 0.00737
[33,    37] Training loss: 0.00765
[33,    38] Training loss: 0.00734
[33,    39] Training loss: 0.00694
[33,    40] Training loss: 0.00747
[33,    41] Training loss: 0.00756
[33,    42] Training loss: 0.00727
[33,    43] Training loss: 0.00747
[33,    44] Training loss: 0.00754
[33,    45] Training loss: 0.00696
[33,    46] Training loss: 0.00714
[33,    47] Training loss: 0.00705
[33,    48] Training loss: 0.00754
[33,    49] Training loss: 0.00715
[33,    50] Training loss: 0.00703
[33,    51] Training loss: 0.00721
[33,    52] Training loss: 0.00722
[33,    53] Training loss: 0.00725
[33,    54] Training loss: 0.00725
[33,    55] Training loss: 0.00725
[33,    56] Training loss: 0.00699
[33,    57] Training loss: 0.00773
[33] Validation loss: 0.00912
[34,     1] Training loss: 0.00888
[34,     2] Training loss: 0.00808
[34,     3] Training loss: 0.00770
[34,     4] Training loss: 0.00826
[34,     5] Training loss: 0.00725
[34,     6] Training loss: 0.00878
[34,     7] Training loss: 0.00820
[34,     8] Training loss: 0.00780
[34,     9] Training loss: 0.00835
[34,    10] Training loss: 0.00791
[34,    11] Training loss: 0.00811
[34,    12] Training loss: 0.00824
[34,    13] Training loss: 0.00790
[34,    14] Training loss: 0.00753
[34,    15] Training loss: 0.00776
[34,    16] Training loss: 0.00780
[34,    17] Training loss: 0.00768
[34,    18] Training loss: 0.00725
[34,    19] Training loss: 0.00785
[34,    20] Training loss: 0.00769
[34,    21] Training loss: 0.00740
[34,    22] Training loss: 0.00806
[34,    23] Training loss: 0.00728
[34,    24] Training loss: 0.00784
[34,    25] Training loss: 0.00714
[34,    26] Training loss: 0.00718
[34,    27] Training loss: 0.00787
[34,    28] Training loss: 0.00742
[34,    29] Training loss: 0.00776
[34,    30] Training loss: 0.00801
[34,    31] Training loss: 0.00740
[34,    32] Training loss: 0.00741
[34,    33] Training loss: 0.00731
[34,    34] Training loss: 0.00759
[34,    35] Training loss: 0.00740
[34,    36] Training loss: 0.00704
[34,    37] Training loss: 0.00727
[34,    38] Training loss: 0.00715
[34,    39] Training loss: 0.00731
[34,    40] Training loss: 0.00688
[34,    41] Training loss: 0.00708
[34,    42] Training loss: 0.00699
[34,    43] Training loss: 0.00707
[34,    44] Training loss: 0.00729
[34,    45] Training loss: 0.00706
[34,    46] Training loss: 0.00715
[34,    47] Training loss: 0.00722
[34,    48] Training loss: 0.00722
[34,    49] Training loss: 0.00695
[34,    50] Training loss: 0.00731
[34,    51] Training loss: 0.00697
[34,    52] Training loss: 0.00732
[34,    53] Training loss: 0.00725
[34,    54] Training loss: 0.00696
[34,    55] Training loss: 0.00740
[34,    56] Training loss: 0.00711
[34,    57] Training loss: 0.00719
[34] Validation loss: 0.00775
[35,     1] Training loss: 0.00671
[35,     2] Training loss: 0.00745
[35,     3] Training loss: 0.00711
[35,     4] Training loss: 0.00668
[35,     5] Training loss: 0.00709
[35,     6] Training loss: 0.00699
[35,     7] Training loss: 0.00712
[35,     8] Training loss: 0.00731
[35,     9] Training loss: 0.00723
[35,    10] Training loss: 0.00681
[35,    11] Training loss: 0.00692
[35,    12] Training loss: 0.00702
[35,    13] Training loss: 0.00683
[35,    14] Training loss: 0.00699
[35,    15] Training loss: 0.00682
[35,    16] Training loss: 0.00705
[35,    17] Training loss: 0.00676
[35,    18] Training loss: 0.00726
[35,    19] Training loss: 0.00706
[35,    20] Training loss: 0.00750
[35,    21] Training loss: 0.00745
[35,    22] Training loss: 0.00705
[35,    23] Training loss: 0.00753
[35,    24] Training loss: 0.00703
[35,    25] Training loss: 0.00709
[35,    26] Training loss: 0.00712
[35,    27] Training loss: 0.00708
[35,    28] Training loss: 0.00713
[35,    29] Training loss: 0.00737
[35,    30] Training loss: 0.00744
[35,    31] Training loss: 0.00693
[35,    32] Training loss: 0.00690
[35,    33] Training loss: 0.00680
[35,    34] Training loss: 0.00712
[35,    35] Training loss: 0.00699
[35,    36] Training loss: 0.00713
[35,    37] Training loss: 0.00696
[35,    38] Training loss: 0.00717
[35,    39] Training loss: 0.00732
[35,    40] Training loss: 0.00742
[35,    41] Training loss: 0.00729
[35,    42] Training loss: 0.00707
[35,    43] Training loss: 0.00710
[35,    44] Training loss: 0.00692
[35,    45] Training loss: 0.00756
[35,    46] Training loss: 0.00725
[35,    47] Training loss: 0.00705
[35,    48] Training loss: 0.00713
[35,    49] Training loss: 0.00714
[35,    50] Training loss: 0.00720
[35,    51] Training loss: 0.00704
[35,    52] Training loss: 0.00724
[35,    53] Training loss: 0.00719
[35,    54] Training loss: 0.00687
[35,    55] Training loss: 0.00729
[35,    56] Training loss: 0.00729
[35,    57] Training loss: 0.00728
[35] Validation loss: 0.00775
[36,     1] Training loss: 0.00748
[36,     2] Training loss: 0.00786
[36,     3] Training loss: 0.00692
[36,     4] Training loss: 0.00694
[36,     5] Training loss: 0.00711
[36,     6] Training loss: 0.00708
[36,     7] Training loss: 0.00719
[36,     8] Training loss: 0.00712
[36,     9] Training loss: 0.00684
[36,    10] Training loss: 0.00741
[36,    11] Training loss: 0.00730
[36,    12] Training loss: 0.00680
[36,    13] Training loss: 0.00703
[36,    14] Training loss: 0.00676
[36,    15] Training loss: 0.00694
[36,    16] Training loss: 0.00691
[36,    17] Training loss: 0.00664
[36,    18] Training loss: 0.00728
[36,    19] Training loss: 0.00680
[36,    20] Training loss: 0.00696
[36,    21] Training loss: 0.00711
[36,    22] Training loss: 0.00673
[36,    23] Training loss: 0.00696
[36,    24] Training loss: 0.00694
[36,    25] Training loss: 0.00679
[36,    26] Training loss: 0.00703
[36,    27] Training loss: 0.00700
[36,    28] Training loss: 0.00678
[36,    29] Training loss: 0.00674
[36,    30] Training loss: 0.00705
[36,    31] Training loss: 0.00677
[36,    32] Training loss: 0.00711
[36,    33] Training loss: 0.00710
[36,    34] Training loss: 0.00709
[36,    35] Training loss: 0.00713
[36,    36] Training loss: 0.00687
[36,    37] Training loss: 0.00739
[36,    38] Training loss: 0.00718
[36,    39] Training loss: 0.00697
[36,    40] Training loss: 0.00722
[36,    41] Training loss: 0.00666
[36,    42] Training loss: 0.00707
[36,    43] Training loss: 0.00693
[36,    44] Training loss: 0.00730
[36,    45] Training loss: 0.00710
[36,    46] Training loss: 0.00662
[36,    47] Training loss: 0.00687
[36,    48] Training loss: 0.00766
[36,    49] Training loss: 0.00722
[36,    50] Training loss: 0.00728
[36,    51] Training loss: 0.00734
[36,    52] Training loss: 0.00719
[36,    53] Training loss: 0.00742
[36,    54] Training loss: 0.00703
[36,    55] Training loss: 0.00691
[36,    56] Training loss: 0.00709
[36,    57] Training loss: 0.00693
[36] Validation loss: 0.00862
[37,     1] Training loss: 0.00753
[37,     2] Training loss: 0.00771
[37,     3] Training loss: 0.00761
[37,     4] Training loss: 0.00714
[37,     5] Training loss: 0.00737
[37,     6] Training loss: 0.00694
[37,     7] Training loss: 0.00693
[37,     8] Training loss: 0.00726
[37,     9] Training loss: 0.00703
[37,    10] Training loss: 0.00693
[37,    11] Training loss: 0.00699
[37,    12] Training loss: 0.00671
[37,    13] Training loss: 0.00682
[37,    14] Training loss: 0.00702
[37,    15] Training loss: 0.00675
[37,    16] Training loss: 0.00702
[37,    17] Training loss: 0.00694
[37,    18] Training loss: 0.00681
[37,    19] Training loss: 0.00723
[37,    20] Training loss: 0.00699
[37,    21] Training loss: 0.00708
[37,    22] Training loss: 0.00668
[37,    23] Training loss: 0.00662
[37,    24] Training loss: 0.00674
[37,    25] Training loss: 0.00680
[37,    26] Training loss: 0.00662
[37,    27] Training loss: 0.00653
[37,    28] Training loss: 0.00698
[37,    29] Training loss: 0.00673
[37,    30] Training loss: 0.00663
[37,    31] Training loss: 0.00672
[37,    32] Training loss: 0.00681
[37,    33] Training loss: 0.00674
[37,    34] Training loss: 0.00669
[37,    35] Training loss: 0.00680
[37,    36] Training loss: 0.00696
[37,    37] Training loss: 0.00692
[37,    38] Training loss: 0.00687
[37,    39] Training loss: 0.00670
[37,    40] Training loss: 0.00681
[37,    41] Training loss: 0.00694
[37,    42] Training loss: 0.00680
[37,    43] Training loss: 0.00710
[37,    44] Training loss: 0.00678
[37,    45] Training loss: 0.00666
[37,    46] Training loss: 0.00695
[37,    47] Training loss: 0.00705
[37,    48] Training loss: 0.00678
[37,    49] Training loss: 0.00673
[37,    50] Training loss: 0.00643
[37,    51] Training loss: 0.00665
[37,    52] Training loss: 0.00663
[37,    53] Training loss: 0.00683
[37,    54] Training loss: 0.00689
[37,    55] Training loss: 0.00662
[37,    56] Training loss: 0.00649
[37,    57] Training loss: 0.00767
[37] Validation loss: 0.00745
[38,     1] Training loss: 0.00683
[38,     2] Training loss: 0.00677
[38,     3] Training loss: 0.00667
[38,     4] Training loss: 0.00656
[38,     5] Training loss: 0.00669
[38,     6] Training loss: 0.00685
[38,     7] Training loss: 0.00681
[38,     8] Training loss: 0.00676
[38,     9] Training loss: 0.00692
[38,    10] Training loss: 0.00674
[38,    11] Training loss: 0.00659
[38,    12] Training loss: 0.00682
[38,    13] Training loss: 0.00670
[38,    14] Training loss: 0.00670
[38,    15] Training loss: 0.00666
[38,    16] Training loss: 0.00673
[38,    17] Training loss: 0.00728
[38,    18] Training loss: 0.00692
[38,    19] Training loss: 0.00674
[38,    20] Training loss: 0.00718
[38,    21] Training loss: 0.00706
[38,    22] Training loss: 0.00705
[38,    23] Training loss: 0.00665
[38,    24] Training loss: 0.00676
[38,    25] Training loss: 0.00669
[38,    26] Training loss: 0.00704
[38,    27] Training loss: 0.00699
[38,    28] Training loss: 0.00698
[38,    29] Training loss: 0.00711
[38,    30] Training loss: 0.00689
[38,    31] Training loss: 0.00693
[38,    32] Training loss: 0.00660
[38,    33] Training loss: 0.00706
[38,    34] Training loss: 0.00714
[38,    35] Training loss: 0.00686
[38,    36] Training loss: 0.00685
[38,    37] Training loss: 0.00674
[38,    38] Training loss: 0.00667
[38,    39] Training loss: 0.00659
[38,    40] Training loss: 0.00658
[38,    41] Training loss: 0.00677
[38,    42] Training loss: 0.00659
[38,    43] Training loss: 0.00667
[38,    44] Training loss: 0.00698
[38,    45] Training loss: 0.00699
[38,    46] Training loss: 0.00694
[38,    47] Training loss: 0.00699
[38,    48] Training loss: 0.00690
[38,    49] Training loss: 0.00740
[38,    50] Training loss: 0.00713
[38,    51] Training loss: 0.00708
[38,    52] Training loss: 0.00699
[38,    53] Training loss: 0.00661
[38,    54] Training loss: 0.00679
[38,    55] Training loss: 0.00720
[38,    56] Training loss: 0.00696
[38,    57] Training loss: 0.00777
[38] Validation loss: 0.00892
[39,     1] Training loss: 0.00822
[39,     2] Training loss: 0.00718
[39,     3] Training loss: 0.00780
[39,     4] Training loss: 0.00827
[39,     5] Training loss: 0.00810
[39,     6] Training loss: 0.00770
[39,     7] Training loss: 0.00781
[39,     8] Training loss: 0.00769
[39,     9] Training loss: 0.00768
[39,    10] Training loss: 0.00748
[39,    11] Training loss: 0.00728
[39,    12] Training loss: 0.00726
[39,    13] Training loss: 0.00716
[39,    14] Training loss: 0.00720
[39,    15] Training loss: 0.00742
[39,    16] Training loss: 0.00709
[39,    17] Training loss: 0.00719
[39,    18] Training loss: 0.00683
[39,    19] Training loss: 0.00715
[39,    20] Training loss: 0.00716
[39,    21] Training loss: 0.00706
[39,    22] Training loss: 0.00680
[39,    23] Training loss: 0.00680
[39,    24] Training loss: 0.00691
[39,    25] Training loss: 0.00648
[39,    26] Training loss: 0.00688
[39,    27] Training loss: 0.00669
[39,    28] Training loss: 0.00674
[39,    29] Training loss: 0.00691
[39,    30] Training loss: 0.00645
[39,    31] Training loss: 0.00673
[39,    32] Training loss: 0.00668
[39,    33] Training loss: 0.00664
[39,    34] Training loss: 0.00664
[39,    35] Training loss: 0.00710
[39,    36] Training loss: 0.00652
[39,    37] Training loss: 0.00687
[39,    38] Training loss: 0.00674
[39,    39] Training loss: 0.00667
[39,    40] Training loss: 0.00699
[39,    41] Training loss: 0.00675
[39,    42] Training loss: 0.00683
[39,    43] Training loss: 0.00711
[39,    44] Training loss: 0.00699
[39,    45] Training loss: 0.00700
[39,    46] Training loss: 0.00687
[39,    47] Training loss: 0.00731
[39,    48] Training loss: 0.00689
[39,    49] Training loss: 0.00682
[39,    50] Training loss: 0.00649
[39,    51] Training loss: 0.00702
[39,    52] Training loss: 0.00672
[39,    53] Training loss: 0.00657
[39,    54] Training loss: 0.00662
[39,    55] Training loss: 0.00676
[39,    56] Training loss: 0.00689
[39,    57] Training loss: 0.00650
[39] Validation loss: 0.00806
[40,     1] Training loss: 0.00694
[40,     2] Training loss: 0.00683
[40,     3] Training loss: 0.00703
[40,     4] Training loss: 0.00763
[40,     5] Training loss: 0.00704
[40,     6] Training loss: 0.00788
[40,     7] Training loss: 0.00732
[40,     8] Training loss: 0.00713
[40,     9] Training loss: 0.00726
[40,    10] Training loss: 0.00725
[40,    11] Training loss: 0.00719
[40,    12] Training loss: 0.00708
[40,    13] Training loss: 0.00738
[40,    14] Training loss: 0.00681
[40,    15] Training loss: 0.00689
[40,    16] Training loss: 0.00684
[40,    17] Training loss: 0.00696
[40,    18] Training loss: 0.00674
[40,    19] Training loss: 0.00641
[40,    20] Training loss: 0.00690
[40,    21] Training loss: 0.00649
[40,    22] Training loss: 0.00672
[40,    23] Training loss: 0.00672
[40,    24] Training loss: 0.00686
[40,    25] Training loss: 0.00682
[40,    26] Training loss: 0.00661
[40,    27] Training loss: 0.00688
[40,    28] Training loss: 0.00671
[40,    29] Training loss: 0.00665
[40,    30] Training loss: 0.00649
[40,    31] Training loss: 0.00646
[40,    32] Training loss: 0.00696
[40,    33] Training loss: 0.00694
[40,    34] Training loss: 0.00672
[40,    35] Training loss: 0.00704
[40,    36] Training loss: 0.00690
[40,    37] Training loss: 0.00660
[40,    38] Training loss: 0.00662
[40,    39] Training loss: 0.00669
[40,    40] Training loss: 0.00695
[40,    41] Training loss: 0.00683
[40,    42] Training loss: 0.00649
[40,    43] Training loss: 0.00656
[40,    44] Training loss: 0.00679
[40,    45] Training loss: 0.00699
[40,    46] Training loss: 0.00663
[40,    47] Training loss: 0.00680
[40,    48] Training loss: 0.00664
[40,    49] Training loss: 0.00642
[40,    50] Training loss: 0.00639
[40,    51] Training loss: 0.00657
[40,    52] Training loss: 0.00673
[40,    53] Training loss: 0.00657
[40,    54] Training loss: 0.00670
[40,    55] Training loss: 0.00662
[40,    56] Training loss: 0.00659
[40,    57] Training loss: 0.00650
[40] Validation loss: 0.00756
[41,     1] Training loss: 0.00635
[41,     2] Training loss: 0.00672
[41,     3] Training loss: 0.00694
[41,     4] Training loss: 0.00665
[41,     5] Training loss: 0.00670
[41,     6] Training loss: 0.00652
[41,     7] Training loss: 0.00659
[41,     8] Training loss: 0.00648
[41,     9] Training loss: 0.00678
[41,    10] Training loss: 0.00642
[41,    11] Training loss: 0.00676
[41,    12] Training loss: 0.00641
[41,    13] Training loss: 0.00650
[41,    14] Training loss: 0.00653
[41,    15] Training loss: 0.00657
[41,    16] Training loss: 0.00645
[41,    17] Training loss: 0.00658
[41,    18] Training loss: 0.00670
[41,    19] Training loss: 0.00682
[41,    20] Training loss: 0.00653
[41,    21] Training loss: 0.00717
[41,    22] Training loss: 0.00663
[41,    23] Training loss: 0.00692
[41,    24] Training loss: 0.00718
[41,    25] Training loss: 0.00729
[41,    26] Training loss: 0.00655
[41,    27] Training loss: 0.00680
[41,    28] Training loss: 0.00726
[41,    29] Training loss: 0.00705
[41,    30] Training loss: 0.00685
[41,    31] Training loss: 0.00685
[41,    32] Training loss: 0.00684
[41,    33] Training loss: 0.00699
[41,    34] Training loss: 0.00709
[41,    35] Training loss: 0.00731
[41,    36] Training loss: 0.00681
[41,    37] Training loss: 0.00632
[41,    38] Training loss: 0.00665
[41,    39] Training loss: 0.00676
[41,    40] Training loss: 0.00663
[41,    41] Training loss: 0.00673
[41,    42] Training loss: 0.00674
[41,    43] Training loss: 0.00634
[41,    44] Training loss: 0.00641
[41,    45] Training loss: 0.00660
[41,    46] Training loss: 0.00662
[41,    47] Training loss: 0.00691
[41,    48] Training loss: 0.00685
[41,    49] Training loss: 0.00660
[41,    50] Training loss: 0.00626
[41,    51] Training loss: 0.00675
[41,    52] Training loss: 0.00670
[41,    53] Training loss: 0.00645
[41,    54] Training loss: 0.00678
[41,    55] Training loss: 0.00678
[41,    56] Training loss: 0.00659
[41,    57] Training loss: 0.00703
[41] Validation loss: 0.00736
[42,     1] Training loss: 0.00680
[42,     2] Training loss: 0.00687
[42,     3] Training loss: 0.00681
[42,     4] Training loss: 0.00676
[42,     5] Training loss: 0.00676
[42,     6] Training loss: 0.00665
[42,     7] Training loss: 0.00664
[42,     8] Training loss: 0.00687
[42,     9] Training loss: 0.00689
[42,    10] Training loss: 0.00664
[42,    11] Training loss: 0.00638
[42,    12] Training loss: 0.00671
[42,    13] Training loss: 0.00674
[42,    14] Training loss: 0.00699
[42,    15] Training loss: 0.00664
[42,    16] Training loss: 0.00650
[42,    17] Training loss: 0.00650
[42,    18] Training loss: 0.00681
[42,    19] Training loss: 0.00637
[42,    20] Training loss: 0.00662
[42,    21] Training loss: 0.00675
[42,    22] Training loss: 0.00650
[42,    23] Training loss: 0.00649
[42,    24] Training loss: 0.00650
[42,    25] Training loss: 0.00662
[42,    26] Training loss: 0.00668
[42,    27] Training loss: 0.00627
[42,    28] Training loss: 0.00639
[42,    29] Training loss: 0.00643
[42,    30] Training loss: 0.00641
[42,    31] Training loss: 0.00642
[42,    32] Training loss: 0.00621
[42,    33] Training loss: 0.00666
[42,    34] Training loss: 0.00658
[42,    35] Training loss: 0.00622
[42,    36] Training loss: 0.00660
[42,    37] Training loss: 0.00653
[42,    38] Training loss: 0.00664
[42,    39] Training loss: 0.00674
[42,    40] Training loss: 0.00643
[42,    41] Training loss: 0.00682
[42,    42] Training loss: 0.00652
[42,    43] Training loss: 0.00659
[42,    44] Training loss: 0.00637
[42,    45] Training loss: 0.00664
[42,    46] Training loss: 0.00701
[42,    47] Training loss: 0.00638
[42,    48] Training loss: 0.00675
[42,    49] Training loss: 0.00707
[42,    50] Training loss: 0.00680
[42,    51] Training loss: 0.00644
[42,    52] Training loss: 0.00631
[42,    53] Training loss: 0.00683
[42,    54] Training loss: 0.00651
[42,    55] Training loss: 0.00651
[42,    56] Training loss: 0.00638
[42,    57] Training loss: 0.00660
[42] Validation loss: 0.00727
[43,     1] Training loss: 0.00663
[43,     2] Training loss: 0.00627
[43,     3] Training loss: 0.00623
[43,     4] Training loss: 0.00627
[43,     5] Training loss: 0.00661
[43,     6] Training loss: 0.00621
[43,     7] Training loss: 0.00645
[43,     8] Training loss: 0.00663
[43,     9] Training loss: 0.00685
[43,    10] Training loss: 0.00736
[43,    11] Training loss: 0.00670
[43,    12] Training loss: 0.00650
[43,    13] Training loss: 0.00719
[43,    14] Training loss: 0.00692
[43,    15] Training loss: 0.00719
[43,    16] Training loss: 0.00738
[43,    17] Training loss: 0.00726
[43,    18] Training loss: 0.00710
[43,    19] Training loss: 0.00704
[43,    20] Training loss: 0.00703
[43,    21] Training loss: 0.00724
[43,    22] Training loss: 0.00665
[43,    23] Training loss: 0.00726
[43,    24] Training loss: 0.00701
[43,    25] Training loss: 0.00688
[43,    26] Training loss: 0.00768
[43,    27] Training loss: 0.00706
[43,    28] Training loss: 0.00655
[43,    29] Training loss: 0.00702
[43,    30] Training loss: 0.00676
[43,    31] Training loss: 0.00648
[43,    32] Training loss: 0.00684
[43,    33] Training loss: 0.00647
[43,    34] Training loss: 0.00659
[43,    35] Training loss: 0.00703
[43,    36] Training loss: 0.00686
[43,    37] Training loss: 0.00633
[43,    38] Training loss: 0.00667
[43,    39] Training loss: 0.00686
[43,    40] Training loss: 0.00648
[43,    41] Training loss: 0.00660
[43,    42] Training loss: 0.00667
[43,    43] Training loss: 0.00652
[43,    44] Training loss: 0.00634
[43,    45] Training loss: 0.00655
[43,    46] Training loss: 0.00676
[43,    47] Training loss: 0.00699
[43,    48] Training loss: 0.00663
[43,    49] Training loss: 0.00639
[43,    50] Training loss: 0.00688
[43,    51] Training loss: 0.00687
[43,    52] Training loss: 0.00692
[43,    53] Training loss: 0.00688
[43,    54] Training loss: 0.00663
[43,    55] Training loss: 0.00697
[43,    56] Training loss: 0.00671
[43,    57] Training loss: 0.00696
[43] Validation loss: 0.00771
[44,     1] Training loss: 0.00690
[44,     2] Training loss: 0.00669
[44,     3] Training loss: 0.00699
[44,     4] Training loss: 0.00661
[44,     5] Training loss: 0.00708
[44,     6] Training loss: 0.00691
[44,     7] Training loss: 0.00664
[44,     8] Training loss: 0.00666
[44,     9] Training loss: 0.00677
[44,    10] Training loss: 0.00623
[44,    11] Training loss: 0.00696
[44,    12] Training loss: 0.00654
[44,    13] Training loss: 0.00653
[44,    14] Training loss: 0.00632
[44,    15] Training loss: 0.00645
[44,    16] Training loss: 0.00660
[44,    17] Training loss: 0.00617
[44,    18] Training loss: 0.00678
[44,    19] Training loss: 0.00650
[44,    20] Training loss: 0.00663
[44,    21] Training loss: 0.00662
[44,    22] Training loss: 0.00619
[44,    23] Training loss: 0.00650
[44,    24] Training loss: 0.00650
[44,    25] Training loss: 0.00641
[44,    26] Training loss: 0.00627
[44,    27] Training loss: 0.00642
[44,    28] Training loss: 0.00613
[44,    29] Training loss: 0.00673
[44,    30] Training loss: 0.00632
[44,    31] Training loss: 0.00657
[44,    32] Training loss: 0.00660
[44,    33] Training loss: 0.00665
[44,    34] Training loss: 0.00649
[44,    35] Training loss: 0.00631
[44,    36] Training loss: 0.00682
[44,    37] Training loss: 0.00672
[44,    38] Training loss: 0.00680
[44,    39] Training loss: 0.00661
[44,    40] Training loss: 0.00681
[44,    41] Training loss: 0.00636
[44,    42] Training loss: 0.00653
[44,    43] Training loss: 0.00672
[44,    44] Training loss: 0.00668
[44,    45] Training loss: 0.00654
[44,    46] Training loss: 0.00604
[44,    47] Training loss: 0.00683
[44,    48] Training loss: 0.00659
[44,    49] Training loss: 0.00638
[44,    50] Training loss: 0.00654
[44,    51] Training loss: 0.00646
[44,    52] Training loss: 0.00641
[44,    53] Training loss: 0.00648
[44,    54] Training loss: 0.00657
[44,    55] Training loss: 0.00674
[44,    56] Training loss: 0.00641
[44,    57] Training loss: 0.00618
[44] Validation loss: 0.00743
[45,     1] Training loss: 0.00679
[45,     2] Training loss: 0.00669
[45,     3] Training loss: 0.00639
[45,     4] Training loss: 0.00671
[45,     5] Training loss: 0.00637
[45,     6] Training loss: 0.00648
[45,     7] Training loss: 0.00653
[45,     8] Training loss: 0.00659
[45,     9] Training loss: 0.00653
[45,    10] Training loss: 0.00635
[45,    11] Training loss: 0.00690
[45,    12] Training loss: 0.00682
[45,    13] Training loss: 0.00656
[45,    14] Training loss: 0.00684
[45,    15] Training loss: 0.00636
[45,    16] Training loss: 0.00697
[45,    17] Training loss: 0.00648
[45,    18] Training loss: 0.00654
[45,    19] Training loss: 0.00679
[45,    20] Training loss: 0.00659
[45,    21] Training loss: 0.00685
[45,    22] Training loss: 0.00659
[45,    23] Training loss: 0.00662
[45,    24] Training loss: 0.00635
[45,    25] Training loss: 0.00658
[45,    26] Training loss: 0.00659
[45,    27] Training loss: 0.00632
[45,    28] Training loss: 0.00633
[45,    29] Training loss: 0.00688
[45,    30] Training loss: 0.00672
[45,    31] Training loss: 0.00654
[45,    32] Training loss: 0.00704
[45,    33] Training loss: 0.00675
[45,    34] Training loss: 0.00678
[45,    35] Training loss: 0.00664
[45,    36] Training loss: 0.00665
[45,    37] Training loss: 0.00677
[45,    38] Training loss: 0.00679
[45,    39] Training loss: 0.00634
[45,    40] Training loss: 0.00634
[45,    41] Training loss: 0.00608
[45,    42] Training loss: 0.00629
[45,    43] Training loss: 0.00626
[45,    44] Training loss: 0.00628
[45,    45] Training loss: 0.00591
[45,    46] Training loss: 0.00674
[45,    47] Training loss: 0.00660
[45,    48] Training loss: 0.00604
[45,    49] Training loss: 0.00663
[45,    50] Training loss: 0.00647
[45,    51] Training loss: 0.00638
[45,    52] Training loss: 0.00705
[45,    53] Training loss: 0.00650
[45,    54] Training loss: 0.00625
[45,    55] Training loss: 0.00668
[45,    56] Training loss: 0.00659
[45,    57] Training loss: 0.00645
[45] Validation loss: 0.00705
[46,     1] Training loss: 0.00647
[46,     2] Training loss: 0.00627
[46,     3] Training loss: 0.00613
[46,     4] Training loss: 0.00621
[46,     5] Training loss: 0.00622
[46,     6] Training loss: 0.00653
[46,     7] Training loss: 0.00630
[46,     8] Training loss: 0.00626
[46,     9] Training loss: 0.00624
[46,    10] Training loss: 0.00636
[46,    11] Training loss: 0.00613
[46,    12] Training loss: 0.00645
[46,    13] Training loss: 0.00632
[46,    14] Training loss: 0.00635
[46,    15] Training loss: 0.00612
[46,    16] Training loss: 0.00590
[46,    17] Training loss: 0.00608
[46,    18] Training loss: 0.00638
[46,    19] Training loss: 0.00632
[46,    20] Training loss: 0.00643
[46,    21] Training loss: 0.00613
[46,    22] Training loss: 0.00630
[46,    23] Training loss: 0.00608
[46,    24] Training loss: 0.00615
[46,    25] Training loss: 0.00625
[46,    26] Training loss: 0.00646
[46,    27] Training loss: 0.00661
[46,    28] Training loss: 0.00601
[46,    29] Training loss: 0.00643
[46,    30] Training loss: 0.00630
[46,    31] Training loss: 0.00611
[46,    32] Training loss: 0.00641
[46,    33] Training loss: 0.00654
[46,    34] Training loss: 0.00597
[46,    35] Training loss: 0.00648
[46,    36] Training loss: 0.00663
[46,    37] Training loss: 0.00632
[46,    38] Training loss: 0.00637
[46,    39] Training loss: 0.00675
[46,    40] Training loss: 0.00657
[46,    41] Training loss: 0.00621
[46,    42] Training loss: 0.00679
[46,    43] Training loss: 0.00642
[46,    44] Training loss: 0.00619
[46,    45] Training loss: 0.00665
[46,    46] Training loss: 0.00684
[46,    47] Training loss: 0.00669
[46,    48] Training loss: 0.00616
[46,    49] Training loss: 0.00656
[46,    50] Training loss: 0.00668
[46,    51] Training loss: 0.00602
[46,    52] Training loss: 0.00713
[46,    53] Training loss: 0.00648
[46,    54] Training loss: 0.00730
[46,    55] Training loss: 0.00636
[46,    56] Training loss: 0.00733
[46,    57] Training loss: 0.00661
[46] Validation loss: 0.00872
[47,     1] Training loss: 0.00763
[47,     2] Training loss: 0.00731
[47,     3] Training loss: 0.00713
[47,     4] Training loss: 0.00741
[47,     5] Training loss: 0.00671
[47,     6] Training loss: 0.00707
[47,     7] Training loss: 0.00654
[47,     8] Training loss: 0.00714
[47,     9] Training loss: 0.00635
[47,    10] Training loss: 0.00637
[47,    11] Training loss: 0.00636
[47,    12] Training loss: 0.00699
[47,    13] Training loss: 0.00631
[47,    14] Training loss: 0.00680
[47,    15] Training loss: 0.00625
[47,    16] Training loss: 0.00667
[47,    17] Training loss: 0.00626
[47,    18] Training loss: 0.00683
[47,    19] Training loss: 0.00609
[47,    20] Training loss: 0.00638
[47,    21] Training loss: 0.00623
[47,    22] Training loss: 0.00645
[47,    23] Training loss: 0.00628
[47,    24] Training loss: 0.00616
[47,    25] Training loss: 0.00603
[47,    26] Training loss: 0.00638
[47,    27] Training loss: 0.00624
[47,    28] Training loss: 0.00611
[47,    29] Training loss: 0.00638
[47,    30] Training loss: 0.00642
[47,    31] Training loss: 0.00653
[47,    32] Training loss: 0.00625
[47,    33] Training loss: 0.00593
[47,    34] Training loss: 0.00621
[47,    35] Training loss: 0.00606
[47,    36] Training loss: 0.00617
[47,    37] Training loss: 0.00653
[47,    38] Training loss: 0.00637
[47,    39] Training loss: 0.00611
[47,    40] Training loss: 0.00638
[47,    41] Training loss: 0.00635
[47,    42] Training loss: 0.00676
[47,    43] Training loss: 0.00621
[47,    44] Training loss: 0.00625
[47,    45] Training loss: 0.00628
[47,    46] Training loss: 0.00641
[47,    47] Training loss: 0.00619
[47,    48] Training loss: 0.00628
[47,    49] Training loss: 0.00607
[47,    50] Training loss: 0.00586
[47,    51] Training loss: 0.00622
[47,    52] Training loss: 0.00598
[47,    53] Training loss: 0.00601
[47,    54] Training loss: 0.00610
[47,    55] Training loss: 0.00619
[47,    56] Training loss: 0.00618
[47,    57] Training loss: 0.00607
[47] Validation loss: 0.00727
[48,     1] Training loss: 0.00617
[48,     2] Training loss: 0.00628
[48,     3] Training loss: 0.00600
[48,     4] Training loss: 0.00627
[48,     5] Training loss: 0.00625
[48,     6] Training loss: 0.00612
[48,     7] Training loss: 0.00594
[48,     8] Training loss: 0.00627
[48,     9] Training loss: 0.00622
[48,    10] Training loss: 0.00605
[48,    11] Training loss: 0.00591
[48,    12] Training loss: 0.00606
[48,    13] Training loss: 0.00626
[48,    14] Training loss: 0.00604
[48,    15] Training loss: 0.00625
[48,    16] Training loss: 0.00608
[48,    17] Training loss: 0.00623
[48,    18] Training loss: 0.00614
[48,    19] Training loss: 0.00606
[48,    20] Training loss: 0.00612
[48,    21] Training loss: 0.00638
[48,    22] Training loss: 0.00648
[48,    23] Training loss: 0.00605
[48,    24] Training loss: 0.00629
[48,    25] Training loss: 0.00621
[48,    26] Training loss: 0.00621
[48,    27] Training loss: 0.00623
[48,    28] Training loss: 0.00618
[48,    29] Training loss: 0.00617
[48,    30] Training loss: 0.00602
[48,    31] Training loss: 0.00663
[48,    32] Training loss: 0.00648
[48,    33] Training loss: 0.00623
[48,    34] Training loss: 0.00630
[48,    35] Training loss: 0.00630
[48,    36] Training loss: 0.00623
[48,    37] Training loss: 0.00623
[48,    38] Training loss: 0.00630
[48,    39] Training loss: 0.00599
[48,    40] Training loss: 0.00620
[48,    41] Training loss: 0.00600
[48,    42] Training loss: 0.00607
[48,    43] Training loss: 0.00593
[48,    44] Training loss: 0.00616
[48,    45] Training loss: 0.00616
[48,    46] Training loss: 0.00641
[48,    47] Training loss: 0.00613
[48,    48] Training loss: 0.00611
[48,    49] Training loss: 0.00593
[48,    50] Training loss: 0.00604
[48,    51] Training loss: 0.00633
[48,    52] Training loss: 0.00643
[48,    53] Training loss: 0.00613
[48,    54] Training loss: 0.00610
[48,    55] Training loss: 0.00640
[48,    56] Training loss: 0.00658
[48,    57] Training loss: 0.00580
[48] Validation loss: 0.00751
[49,     1] Training loss: 0.00640
[49,     2] Training loss: 0.00616
[49,     3] Training loss: 0.00630
[49,     4] Training loss: 0.00601
[49,     5] Training loss: 0.00632
[49,     6] Training loss: 0.00675
[49,     7] Training loss: 0.00640
[49,     8] Training loss: 0.00597
[49,     9] Training loss: 0.00630
[49,    10] Training loss: 0.00621
[49,    11] Training loss: 0.00618
[49,    12] Training loss: 0.00601
[49,    13] Training loss: 0.00619
[49,    14] Training loss: 0.00610
[49,    15] Training loss: 0.00608
[49,    16] Training loss: 0.00595
[49,    17] Training loss: 0.00574
[49,    18] Training loss: 0.00641
[49,    19] Training loss: 0.00601
[49,    20] Training loss: 0.00626
[49,    21] Training loss: 0.00594
[49,    22] Training loss: 0.00601
[49,    23] Training loss: 0.00613
[49,    24] Training loss: 0.00616
[49,    25] Training loss: 0.00615
[49,    26] Training loss: 0.00624
[49,    27] Training loss: 0.00689
[49,    28] Training loss: 0.00647
[49,    29] Training loss: 0.00622
[49,    30] Training loss: 0.00631
[49,    31] Training loss: 0.00652
[49,    32] Training loss: 0.00625
[49,    33] Training loss: 0.00656
[49,    34] Training loss: 0.00663
[49,    35] Training loss: 0.00683
[49,    36] Training loss: 0.00652
[49,    37] Training loss: 0.00618
[49,    38] Training loss: 0.00639
[49,    39] Training loss: 0.00610
[49,    40] Training loss: 0.00643
[49,    41] Training loss: 0.00626
[49,    42] Training loss: 0.00601
[49,    43] Training loss: 0.00607
[49,    44] Training loss: 0.00616
[49,    45] Training loss: 0.00665
[49,    46] Training loss: 0.00624
[49,    47] Training loss: 0.00607
[49,    48] Training loss: 0.00573
[49,    49] Training loss: 0.00704
[49,    50] Training loss: 0.00598
[49,    51] Training loss: 0.00616
[49,    52] Training loss: 0.00613
[49,    53] Training loss: 0.00615
[49,    54] Training loss: 0.00646
[49,    55] Training loss: 0.00627
[49,    56] Training loss: 0.00643
[49,    57] Training loss: 0.00635
[49] Validation loss: 0.00733
[50,     1] Training loss: 0.00622
[50,     2] Training loss: 0.00648
[50,     3] Training loss: 0.00633
[50,     4] Training loss: 0.00623
[50,     5] Training loss: 0.00668
[50,     6] Training loss: 0.00625
[50,     7] Training loss: 0.00594
[50,     8] Training loss: 0.00634
[50,     9] Training loss: 0.00602
[50,    10] Training loss: 0.00649
[50,    11] Training loss: 0.00631
[50,    12] Training loss: 0.00637
[50,    13] Training loss: 0.00631
[50,    14] Training loss: 0.00580
[50,    15] Training loss: 0.00596
[50,    16] Training loss: 0.00630
[50,    17] Training loss: 0.00639
[50,    18] Training loss: 0.00614
[50,    19] Training loss: 0.00598
[50,    20] Training loss: 0.00603
[50,    21] Training loss: 0.00606
[50,    22] Training loss: 0.00637
[50,    23] Training loss: 0.00599
[50,    24] Training loss: 0.00611
[50,    25] Training loss: 0.00581
[50,    26] Training loss: 0.00608
[50,    27] Training loss: 0.00579
[50,    28] Training loss: 0.00597
[50,    29] Training loss: 0.00590
[50,    30] Training loss: 0.00598
[50,    31] Training loss: 0.00597
[50,    32] Training loss: 0.00573
[50,    33] Training loss: 0.00604
[50,    34] Training loss: 0.00593
[50,    35] Training loss: 0.00587
[50,    36] Training loss: 0.00578
[50,    37] Training loss: 0.00598
[50,    38] Training loss: 0.00601
[50,    39] Training loss: 0.00576
[50,    40] Training loss: 0.00599
[50,    41] Training loss: 0.00591
[50,    42] Training loss: 0.00588
[50,    43] Training loss: 0.00563
[50,    44] Training loss: 0.00578
[50,    45] Training loss: 0.00574
[50,    46] Training loss: 0.00605
[50,    47] Training loss: 0.00625
[50,    48] Training loss: 0.00626
[50,    49] Training loss: 0.00589
[50,    50] Training loss: 0.00632
[50,    51] Training loss: 0.00621
[50,    52] Training loss: 0.00573
[50,    53] Training loss: 0.00600
[50,    54] Training loss: 0.00616
[50,    55] Training loss: 0.00625
[50,    56] Training loss: 0.00658
[50,    57] Training loss: 0.00636
[50] Validation loss: 0.00731
[51,     1] Training loss: 0.00619
[51,     2] Training loss: 0.00610
[51,     3] Training loss: 0.00611
[51,     4] Training loss: 0.00602
[51,     5] Training loss: 0.00644
[51,     6] Training loss: 0.00622
[51,     7] Training loss: 0.00624
[51,     8] Training loss: 0.00598
[51,     9] Training loss: 0.00594
[51,    10] Training loss: 0.00629
[51,    11] Training loss: 0.00677
[51,    12] Training loss: 0.00618
[51,    13] Training loss: 0.00623
[51,    14] Training loss: 0.00622
[51,    15] Training loss: 0.00603
[51,    16] Training loss: 0.00593
[51,    17] Training loss: 0.00611
[51,    18] Training loss: 0.00620
[51,    19] Training loss: 0.00609
[51,    20] Training loss: 0.00601
[51,    21] Training loss: 0.00630
[51,    22] Training loss: 0.00615
[51,    23] Training loss: 0.00633
[51,    24] Training loss: 0.00601
[51,    25] Training loss: 0.00593
[51,    26] Training loss: 0.00601
[51,    27] Training loss: 0.00605
[51,    28] Training loss: 0.00580
[51,    29] Training loss: 0.00604
[51,    30] Training loss: 0.00602
[51,    31] Training loss: 0.00604
[51,    32] Training loss: 0.00603
[51,    33] Training loss: 0.00590
[51,    34] Training loss: 0.00602
[51,    35] Training loss: 0.00563
[51,    36] Training loss: 0.00587
[51,    37] Training loss: 0.00613
[51,    38] Training loss: 0.00597
[51,    39] Training loss: 0.00584
[51,    40] Training loss: 0.00587
[51,    41] Training loss: 0.00587
[51,    42] Training loss: 0.00614
[51,    43] Training loss: 0.00606
[51,    44] Training loss: 0.00586
[51,    45] Training loss: 0.00605
[51,    46] Training loss: 0.00599
[51,    47] Training loss: 0.00595
[51,    48] Training loss: 0.00580
[51,    49] Training loss: 0.00605
[51,    50] Training loss: 0.00601
[51,    51] Training loss: 0.00621
[51,    52] Training loss: 0.00592
[51,    53] Training loss: 0.00587
[51,    54] Training loss: 0.00647
[51,    55] Training loss: 0.00634
[51,    56] Training loss: 0.00584
[51,    57] Training loss: 0.00591
[51] Validation loss: 0.00778
[52,     1] Training loss: 0.00714
[52,     2] Training loss: 0.00680
[52,     3] Training loss: 0.00611
[52,     4] Training loss: 0.00681
[52,     5] Training loss: 0.00645
[52,     6] Training loss: 0.00633
[52,     7] Training loss: 0.00614
[52,     8] Training loss: 0.00639
[52,     9] Training loss: 0.00583
[52,    10] Training loss: 0.00621
[52,    11] Training loss: 0.00615
[52,    12] Training loss: 0.00592
[52,    13] Training loss: 0.00597
[52,    14] Training loss: 0.00587
[52,    15] Training loss: 0.00606
[52,    16] Training loss: 0.00581
[52,    17] Training loss: 0.00588
[52,    18] Training loss: 0.00571
[52,    19] Training loss: 0.00592
[52,    20] Training loss: 0.00583
[52,    21] Training loss: 0.00601
[52,    22] Training loss: 0.00586
[52,    23] Training loss: 0.00616
[52,    24] Training loss: 0.00589
[52,    25] Training loss: 0.00577
[52,    26] Training loss: 0.00602
[52,    27] Training loss: 0.00573
[52,    28] Training loss: 0.00572
[52,    29] Training loss: 0.00592
[52,    30] Training loss: 0.00580
[52,    31] Training loss: 0.00596
[52,    32] Training loss: 0.00571
[52,    33] Training loss: 0.00588
[52,    34] Training loss: 0.00572
[52,    35] Training loss: 0.00584
[52,    36] Training loss: 0.00610
[52,    37] Training loss: 0.00570
[52,    38] Training loss: 0.00621
[52,    39] Training loss: 0.00601
[52,    40] Training loss: 0.00595
[52,    41] Training loss: 0.00603
[52,    42] Training loss: 0.00614
[52,    43] Training loss: 0.00617
[52,    44] Training loss: 0.00635
[52,    45] Training loss: 0.00621
[52,    46] Training loss: 0.00581
[52,    47] Training loss: 0.00614
[52,    48] Training loss: 0.00586
[52,    49] Training loss: 0.00603
[52,    50] Training loss: 0.00600
[52,    51] Training loss: 0.00595
[52,    52] Training loss: 0.00630
[52,    53] Training loss: 0.00609
[52,    54] Training loss: 0.00624
[52,    55] Training loss: 0.00593
[52,    56] Training loss: 0.00615
[52,    57] Training loss: 0.00594
[52] Validation loss: 0.00771
[53,     1] Training loss: 0.00665
[53,     2] Training loss: 0.00628
[53,     3] Training loss: 0.00617
[53,     4] Training loss: 0.00627
[53,     5] Training loss: 0.00613
[53,     6] Training loss: 0.00622
[53,     7] Training loss: 0.00632
[53,     8] Training loss: 0.00660
[53,     9] Training loss: 0.00598
[53,    10] Training loss: 0.00608
[53,    11] Training loss: 0.00597
[53,    12] Training loss: 0.00588
[53,    13] Training loss: 0.00598
[53,    14] Training loss: 0.00627
[53,    15] Training loss: 0.00576
[53,    16] Training loss: 0.00603
[53,    17] Training loss: 0.00611
[53,    18] Training loss: 0.00612
[53,    19] Training loss: 0.00614
[53,    20] Training loss: 0.00619
[53,    21] Training loss: 0.00628
[53,    22] Training loss: 0.00636
[53,    23] Training loss: 0.00629
[53,    24] Training loss: 0.00608
[53,    25] Training loss: 0.00598
[53,    26] Training loss: 0.00620
[53,    27] Training loss: 0.00604
[53,    28] Training loss: 0.00600
[53,    29] Training loss: 0.00585
[53,    30] Training loss: 0.00607
[53,    31] Training loss: 0.00608
[53,    32] Training loss: 0.00614
[53,    33] Training loss: 0.00599
[53,    34] Training loss: 0.00613
[53,    35] Training loss: 0.00618
[53,    36] Training loss: 0.00631
[53,    37] Training loss: 0.00625
[53,    38] Training loss: 0.00642
[53,    39] Training loss: 0.00598
[53,    40] Training loss: 0.00633
[53,    41] Training loss: 0.00583
[53,    42] Training loss: 0.00621
[53,    43] Training loss: 0.00573
[53,    44] Training loss: 0.00582
[53,    45] Training loss: 0.00578
[53,    46] Training loss: 0.00586
[53,    47] Training loss: 0.00589
[53,    48] Training loss: 0.00575
[53,    49] Training loss: 0.00597
[53,    50] Training loss: 0.00571
[53,    51] Training loss: 0.00557
[53,    52] Training loss: 0.00562
[53,    53] Training loss: 0.00570
[53,    54] Training loss: 0.00595
[53,    55] Training loss: 0.00586
[53,    56] Training loss: 0.00577
[53,    57] Training loss: 0.00577
[53] Validation loss: 0.00753
[54,     1] Training loss: 0.00599
[54,     2] Training loss: 0.00595
[54,     3] Training loss: 0.00603
[54,     4] Training loss: 0.00578
[54,     5] Training loss: 0.00569
[54,     6] Training loss: 0.00600
[54,     7] Training loss: 0.00614
[54,     8] Training loss: 0.00568
[54,     9] Training loss: 0.00588
[54,    10] Training loss: 0.00584
[54,    11] Training loss: 0.00582
[54,    12] Training loss: 0.00597
[54,    13] Training loss: 0.00594
[54,    14] Training loss: 0.00555
[54,    15] Training loss: 0.00568
[54,    16] Training loss: 0.00567
[54,    17] Training loss: 0.00590
[54,    18] Training loss: 0.00581
[54,    19] Training loss: 0.00577
[54,    20] Training loss: 0.00575
[54,    21] Training loss: 0.00565
[54,    22] Training loss: 0.00549
[54,    23] Training loss: 0.00608
[54,    24] Training loss: 0.00571
[54,    25] Training loss: 0.00560
[54,    26] Training loss: 0.00558
[54,    27] Training loss: 0.00589
[54,    28] Training loss: 0.00564
[54,    29] Training loss: 0.00583
[54,    30] Training loss: 0.00568
[54,    31] Training loss: 0.00576
[54,    32] Training loss: 0.00574
[54,    33] Training loss: 0.00570
[54,    34] Training loss: 0.00600
[54,    35] Training loss: 0.00613
[54,    36] Training loss: 0.00615
[54,    37] Training loss: 0.00606
[54,    38] Training loss: 0.00579
[54,    39] Training loss: 0.00594
[54,    40] Training loss: 0.00589
[54,    41] Training loss: 0.00588
[54,    42] Training loss: 0.00609
[54,    43] Training loss: 0.00582
[54,    44] Training loss: 0.00593
[54,    45] Training loss: 0.00600
[54,    46] Training loss: 0.00591
[54,    47] Training loss: 0.00571
[54,    48] Training loss: 0.00577
[54,    49] Training loss: 0.00570
[54,    50] Training loss: 0.00609
[54,    51] Training loss: 0.00601
[54,    52] Training loss: 0.00600
[54,    53] Training loss: 0.00601
[54,    54] Training loss: 0.00586
[54,    55] Training loss: 0.00573
[54,    56] Training loss: 0.00565
[54,    57] Training loss: 0.00610
[54] Validation loss: 0.00753
[55,     1] Training loss: 0.00636
[55,     2] Training loss: 0.00562
[55,     3] Training loss: 0.00628
[55,     4] Training loss: 0.00621
[55,     5] Training loss: 0.00604
[55,     6] Training loss: 0.00640
[55,     7] Training loss: 0.00641
[55,     8] Training loss: 0.00653
[55,     9] Training loss: 0.00703
[55,    10] Training loss: 0.00634
[55,    11] Training loss: 0.00651
[55,    12] Training loss: 0.00622
[55,    13] Training loss: 0.00683
[55,    14] Training loss: 0.00639
[55,    15] Training loss: 0.00642
[55,    16] Training loss: 0.00645
[55,    17] Training loss: 0.00650
[55,    18] Training loss: 0.00643
[55,    19] Training loss: 0.00636
[55,    20] Training loss: 0.00601
[55,    21] Training loss: 0.00624
[55,    22] Training loss: 0.00596
[55,    23] Training loss: 0.00632
[55,    24] Training loss: 0.00602
[55,    25] Training loss: 0.00603
[55,    26] Training loss: 0.00602
[55,    27] Training loss: 0.00597
[55,    28] Training loss: 0.00592
[55,    29] Training loss: 0.00562
[55,    30] Training loss: 0.00585
[55,    31] Training loss: 0.00572
[55,    32] Training loss: 0.00574
[55,    33] Training loss: 0.00598
[55,    34] Training loss: 0.00603
[55,    35] Training loss: 0.00571
[55,    36] Training loss: 0.00577
[55,    37] Training loss: 0.00566
[55,    38] Training loss: 0.00587
[55,    39] Training loss: 0.00575
[55,    40] Training loss: 0.00595
[55,    41] Training loss: 0.00584
[55,    42] Training loss: 0.00552
[55,    43] Training loss: 0.00546
[55,    44] Training loss: 0.00542
[55,    45] Training loss: 0.00551
[55,    46] Training loss: 0.00551
[55,    47] Training loss: 0.00565
[55,    48] Training loss: 0.00588
[55,    49] Training loss: 0.00592
[55,    50] Training loss: 0.00571
[55,    51] Training loss: 0.00565
[55,    52] Training loss: 0.00592
[55,    53] Training loss: 0.00561
[55,    54] Training loss: 0.00593
[55,    55] Training loss: 0.00583
[55,    56] Training loss: 0.00560
[55,    57] Training loss: 0.00586
[55] Validation loss: 0.00725
[56,     1] Training loss: 0.00591
[56,     2] Training loss: 0.00558
[56,     3] Training loss: 0.00612
[56,     4] Training loss: 0.00573
[56,     5] Training loss: 0.00622
[56,     6] Training loss: 0.00615
[56,     7] Training loss: 0.00573
[56,     8] Training loss: 0.00592
[56,     9] Training loss: 0.00599
[56,    10] Training loss: 0.00620
[56,    11] Training loss: 0.00605
[56,    12] Training loss: 0.00589
[56,    13] Training loss: 0.00601
[56,    14] Training loss: 0.00609
[56,    15] Training loss: 0.00571
[56,    16] Training loss: 0.00591
[56,    17] Training loss: 0.00561
[56,    18] Training loss: 0.00562
[56,    19] Training loss: 0.00581
[56,    20] Training loss: 0.00578
[56,    21] Training loss: 0.00560
[56,    22] Training loss: 0.00554
[56,    23] Training loss: 0.00586
[56,    24] Training loss: 0.00567
[56,    25] Training loss: 0.00590
[56,    26] Training loss: 0.00579
[56,    27] Training loss: 0.00559
[56,    28] Training loss: 0.00580
[56,    29] Training loss: 0.00563
[56,    30] Training loss: 0.00580
[56,    31] Training loss: 0.00596
[56,    32] Training loss: 0.00587
[56,    33] Training loss: 0.00550
[56,    34] Training loss: 0.00551
[56,    35] Training loss: 0.00547
[56,    36] Training loss: 0.00563
[56,    37] Training loss: 0.00539
[56,    38] Training loss: 0.00587
[56,    39] Training loss: 0.00550
[56,    40] Training loss: 0.00557
[56,    41] Training loss: 0.00584
[56,    42] Training loss: 0.00563
[56,    43] Training loss: 0.00569
[56,    44] Training loss: 0.00558
[56,    45] Training loss: 0.00579
[56,    46] Training loss: 0.00591
[56,    47] Training loss: 0.00605
[56,    48] Training loss: 0.00581
[56,    49] Training loss: 0.00570
[56,    50] Training loss: 0.00581
[56,    51] Training loss: 0.00618
[56,    52] Training loss: 0.00570
[56,    53] Training loss: 0.00589
[56,    54] Training loss: 0.00593
[56,    55] Training loss: 0.00579
[56,    56] Training loss: 0.00573
[56,    57] Training loss: 0.00596
[56] Validation loss: 0.00750
[57,     1] Training loss: 0.00635
[57,     2] Training loss: 0.00649
[57,     3] Training loss: 0.00617
[57,     4] Training loss: 0.00600
[57,     5] Training loss: 0.00576
[57,     6] Training loss: 0.00602
[57,     7] Training loss: 0.00583
[57,     8] Training loss: 0.00582
[57,     9] Training loss: 0.00592
[57,    10] Training loss: 0.00607
[57,    11] Training loss: 0.00593
[57,    12] Training loss: 0.00583
[57,    13] Training loss: 0.00603
[57,    14] Training loss: 0.00569
[57,    15] Training loss: 0.00592
[57,    16] Training loss: 0.00573
[57,    17] Training loss: 0.00619
[57,    18] Training loss: 0.00580
[57,    19] Training loss: 0.00583
[57,    20] Training loss: 0.00593
[57,    21] Training loss: 0.00569
[57,    22] Training loss: 0.00589
[57,    23] Training loss: 0.00589
[57,    24] Training loss: 0.00575
[57,    25] Training loss: 0.00583
[57,    26] Training loss: 0.00569
[57,    27] Training loss: 0.00592
[57,    28] Training loss: 0.00604
[57,    29] Training loss: 0.00546
[57,    30] Training loss: 0.00551
[57,    31] Training loss: 0.00592
[57,    32] Training loss: 0.00579
[57,    33] Training loss: 0.00577
[57,    34] Training loss: 0.00577
[57,    35] Training loss: 0.00595
[57,    36] Training loss: 0.00553
[57,    37] Training loss: 0.00571
[57,    38] Training loss: 0.00564
[57,    39] Training loss: 0.00581
[57,    40] Training loss: 0.00566
[57,    41] Training loss: 0.00544
[57,    42] Training loss: 0.00572
[57,    43] Training loss: 0.00557
[57,    44] Training loss: 0.00573
[57,    45] Training loss: 0.00583
[57,    46] Training loss: 0.00564
[57,    47] Training loss: 0.00588
[57,    48] Training loss: 0.00570
[57,    49] Training loss: 0.00577
[57,    50] Training loss: 0.00568
[57,    51] Training loss: 0.00544
[57,    52] Training loss: 0.00628
[57,    53] Training loss: 0.00637
[57,    54] Training loss: 0.00606
[57,    55] Training loss: 0.00577
[57,    56] Training loss: 0.00598
[57,    57] Training loss: 0.00579
[57] Validation loss: 0.00743
[58,     1] Training loss: 0.00578
[58,     2] Training loss: 0.00602
[58,     3] Training loss: 0.00561
[58,     4] Training loss: 0.00652
[58,     5] Training loss: 0.00595
[58,     6] Training loss: 0.00549
[58,     7] Training loss: 0.00611
[58,     8] Training loss: 0.00572
[58,     9] Training loss: 0.00567
[58,    10] Training loss: 0.00571
[58,    11] Training loss: 0.00566
[58,    12] Training loss: 0.00560
[58,    13] Training loss: 0.00565
[58,    14] Training loss: 0.00541
[58,    15] Training loss: 0.00568
[58,    16] Training loss: 0.00569
[58,    17] Training loss: 0.00559
[58,    18] Training loss: 0.00535
[58,    19] Training loss: 0.00573
[58,    20] Training loss: 0.00595
[58,    21] Training loss: 0.00577
[58,    22] Training loss: 0.00553
[58,    23] Training loss: 0.00575
[58,    24] Training loss: 0.00576
[58,    25] Training loss: 0.00586
[58,    26] Training loss: 0.00557
[58,    27] Training loss: 0.00566
[58,    28] Training loss: 0.00593
[58,    29] Training loss: 0.00532
[58,    30] Training loss: 0.00597
[58,    31] Training loss: 0.00562
[58,    32] Training loss: 0.00582
[58,    33] Training loss: 0.00579
[58,    34] Training loss: 0.00563
[58,    35] Training loss: 0.00530
[58,    36] Training loss: 0.00548
[58,    37] Training loss: 0.00567
[58,    38] Training loss: 0.00613
[58,    39] Training loss: 0.00552
[58,    40] Training loss: 0.00569
[58,    41] Training loss: 0.00614
[58,    42] Training loss: 0.00604
[58,    43] Training loss: 0.00635
[58,    44] Training loss: 0.00632
[58,    45] Training loss: 0.00608
[58,    46] Training loss: 0.00625
[58,    47] Training loss: 0.00592
[58,    48] Training loss: 0.00599
[58,    49] Training loss: 0.00631
[58,    50] Training loss: 0.00573
[58,    51] Training loss: 0.00582
[58,    52] Training loss: 0.00607
[58,    53] Training loss: 0.00617
[58,    54] Training loss: 0.00650
[58,    55] Training loss: 0.00597
[58,    56] Training loss: 0.00680
[58,    57] Training loss: 0.00673
[58] Validation loss: 0.00733
[59,     1] Training loss: 0.00631
[59,     2] Training loss: 0.00706
[59,     3] Training loss: 0.00643
[59,     4] Training loss: 0.00664
[59,     5] Training loss: 0.00669
[59,     6] Training loss: 0.00577
[59,     7] Training loss: 0.00652
[59,     8] Training loss: 0.00633
[59,     9] Training loss: 0.00588
[59,    10] Training loss: 0.00622
[59,    11] Training loss: 0.00575
[59,    12] Training loss: 0.00581
[59,    13] Training loss: 0.00608
[59,    14] Training loss: 0.00569
[59,    15] Training loss: 0.00585
[59,    16] Training loss: 0.00581
[59,    17] Training loss: 0.00578
[59,    18] Training loss: 0.00590
[59,    19] Training loss: 0.00563
[59,    20] Training loss: 0.00577
[59,    21] Training loss: 0.00541
[59,    22] Training loss: 0.00573
[59,    23] Training loss: 0.00550
[59,    24] Training loss: 0.00551
[59,    25] Training loss: 0.00603
[59,    26] Training loss: 0.00559
[59,    27] Training loss: 0.00545
[59,    28] Training loss: 0.00566
[59,    29] Training loss: 0.00552
[59,    30] Training loss: 0.00545
[59,    31] Training loss: 0.00577
[59,    32] Training loss: 0.00543
[59,    33] Training loss: 0.00564
[59,    34] Training loss: 0.00547
[59,    35] Training loss: 0.00569
[59,    36] Training loss: 0.00545
[59,    37] Training loss: 0.00565
[59,    38] Training loss: 0.00541
[59,    39] Training loss: 0.00546
[59,    40] Training loss: 0.00544
[59,    41] Training loss: 0.00583
[59,    42] Training loss: 0.00578
[59,    43] Training loss: 0.00534
[59,    44] Training loss: 0.00556
[59,    45] Training loss: 0.00566
[59,    46] Training loss: 0.00555
[59,    47] Training loss: 0.00545
[59,    48] Training loss: 0.00575
[59,    49] Training loss: 0.00567
[59,    50] Training loss: 0.00572
[59,    51] Training loss: 0.00566
[59,    52] Training loss: 0.00536
[59,    53] Training loss: 0.00565
[59,    54] Training loss: 0.00563
[59,    55] Training loss: 0.00594
[59,    56] Training loss: 0.00553
[59,    57] Training loss: 0.00563
[59] Validation loss: 0.00745
[60,     1] Training loss: 0.00640
[60,     2] Training loss: 0.00605
[60,     3] Training loss: 0.00647
[60,     4] Training loss: 0.00585
[60,     5] Training loss: 0.00560
[60,     6] Training loss: 0.00601
[60,     7] Training loss: 0.00568
[60,     8] Training loss: 0.00586
[60,     9] Training loss: 0.00549
[60,    10] Training loss: 0.00562
[60,    11] Training loss: 0.00545
[60,    12] Training loss: 0.00534
[60,    13] Training loss: 0.00572
[60,    14] Training loss: 0.00552
[60,    15] Training loss: 0.00557
[60,    16] Training loss: 0.00545
[60,    17] Training loss: 0.00543
[60,    18] Training loss: 0.00563
[60,    19] Training loss: 0.00564
[60,    20] Training loss: 0.00569
[60,    21] Training loss: 0.00613
[60,    22] Training loss: 0.00569
[60,    23] Training loss: 0.00573
[60,    24] Training loss: 0.00580
[60,    25] Training loss: 0.00553
[60,    26] Training loss: 0.00582
[60,    27] Training loss: 0.00564
[60,    28] Training loss: 0.00550
[60,    29] Training loss: 0.00531
[60,    30] Training loss: 0.00559
[60,    31] Training loss: 0.00579
[60,    32] Training loss: 0.00519
[60,    33] Training loss: 0.00568
[60,    34] Training loss: 0.00550
[60,    35] Training loss: 0.00544
[60,    36] Training loss: 0.00539
[60,    37] Training loss: 0.00542
[60,    38] Training loss: 0.00531
[60,    39] Training loss: 0.00540
[60,    40] Training loss: 0.00561
[60,    41] Training loss: 0.00549
[60,    42] Training loss: 0.00538
[60,    43] Training loss: 0.00552
[60,    44] Training loss: 0.00535
[60,    45] Training loss: 0.00568
[60,    46] Training loss: 0.00544
[60,    47] Training loss: 0.00554
[60,    48] Training loss: 0.00552
[60,    49] Training loss: 0.00541
[60,    50] Training loss: 0.00544
[60,    51] Training loss: 0.00563
[60,    52] Training loss: 0.00533
[60,    53] Training loss: 0.00536
[60,    54] Training loss: 0.00530
[60,    55] Training loss: 0.00531
[60,    56] Training loss: 0.00556
[60,    57] Training loss: 0.00549
[60] Validation loss: 0.00712
[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/[39mcou[0m[49m[39m/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°3 [39m!2 [39m?2[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004hCCUDA_VISIBLE_DEVICES=0 python inference_to_one.py --src_wav data/ycm/input2.wav --ckpt exps/bzn_model_res/bnf-vc-to-one [K--res-44.pt --save_dir data/ycm/output_reM[13D[32mp[32my[32mt[32mh[32mo[32mn[39m [4mi[4mn[4mf[4me[4mr[4me[4mn[4mc[4me[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m.[4mp[4my[24m[11C[4md[4ma[4mt[4ma[4m/[4my[4mc[4mm[4m/[4mi[4mn[4mp[4mu[4mt[4m2[4m.[4mw[4ma[4mv[24m[8C[4me[4mx[4mp[4ms[4m/[4mb[4mz[4mn[4m_[4mm[4mo[4md[4me[4ml[4m_[4mr[4me[4ms[4m/[4mb[4mn[4mf[4m-[4mv[4mc[4m-[4mt[4mo[4m-[4mo[4mn[4me[4m-[4mr[4me[4ms[4m-[4m4[4m4[4m.[4mp[4mt[24m[30CsM[37D[3mC[3mU[3mD[3mA[3m_[3mV[3mI[3mS[3mI[3mB[3mL[3mE[3m_[3mD[3mE[3mV[3mI[3mC[3mE[3mS[3m=[3m0[3m [39m[3mp[39m[3my[39m[3mt[39m[3mh[39m[3mo[39m[3mn[3m [24m[3mi[24m[3mn[24m[3mf[24m[3me[24m[3mr[24m[3me[24m[3mn[24m[3mc[24m[3me[24m[3m_[24m[3mt[24m[3mo[24m[3m_[24m[3mo[24m[3mn[24m[3me[24m[3m.[24m[3mp[24m[3my[3m [3m-[3m-[3ms[3mr[3mc[3m_[3mw[3ma[3mv[3m [24m[3md[24m[3ma[24m[3mt[24m[3ma[24m[3m/[24m[3my[24m[3mc[24m[3mm[24m[3m/[24m[3mi[24m[3mn[24m[3mp[24m[3mu[24m[3mt[24m[3m2[24m[3m.[24m[3mw[24m[3ma[24m[3mv[3m [3m-[3m-[3mc[3mk[3mp[3mt[3m [24m[3me[24m[3mx[24m[3mp[24m[3ms[24m[3m/[24m[3mb[24m[3mz[24m[3mn[24m[3m_[24m[3mm[24m[3mo[24m[3md[24m[3me[24m[3ml[24m[3m_[24m[3mr[24m[3me[24m[3ms[24m[3m/[24m[3mb[24m[3mn[24m[3mf[24m[3m-[24m[3mv[24m[3mc[24m[3m-[24m[3mt[24m[3mo[24m[3m-[24m[3mo[24m[3mn[24m[3me[3m-[24m[3mr[24m[3me[24m[3ms[24m[3m-[24m[3m4[24m[3m4[24m[3m.[24m[3mp[24m[3mt[3m [3m-[3m-[3ms[3ma[3mv[3me[3m_[3md[3mi[3mr[3m [3md[3ma[3mt[3ma[3m/[3my[3mc[3mm[3m/[3mo[3mu[3mt[3mp[3mu[3mt[3m_[3mr[3me[3ms[23mM[37D[23mC[23mU[23mD[23mA[23m_[23mV[23mI[23mS[23mI[23mB[23mL[23mE[23m_[23mD[23mE[23mV[23mI[23mC[23mE[23mS[23m=[23m0[23m [23mp[23my[23mt[23mh[23mo[23mn[23m [23mi[23mn[23mf[23me[23mr[23me[23mn[23mc[23me[23m_[23mt[23mo[23m_[23mo[23mn[23me[23m.[23mp[23my[23m [23m-[23m-[23ms[23mr[23mc[23m_[23mw[23ma[23mv[23m [23md[23ma[23mt[23ma[23m/[23my[23mc[23mm[23m/[23mi[23mn[23mp[23mu[23mt[23m2[23m.[23mw[23ma[23mv[23m [23m-[23m-[23mc[23mk[23mp[23mt[23m [23me[23mx[23mp[23ms[23m/[23mb[23mz[23mn[23m_[23mm[23mo[23md[23me[23ml[23m_[23mr[23me[23ms[23m/[23mb[23mn[23mf[23m-[23mv[23mc[23m-[23mt[23mo[23m-[23mo[23mn[23me-[23mr[23me[23ms[23m-[23m4[23m4[23m.[23mp[23mt[23m [23m-[23m-[23ms[23ma[23mv[23me[23m_[23md[23mi[23mr[23m [23md[23ma[23mt[23ma[23m/[23my[23mc[23mm[23m/[23mo[23mu[23mt[23mp[23mu[23mt[23m_[23mr[23me[23msM[14D[32mp[32my[32mt[32mh[32mo[32mn[39m [4mi[4mn[4mf[4me[4mr[4me[4mn[4mc[4me[4m_[4mt[4mo[4m_[4mo[4mn[4me[4m.[4mp[4my[24m[11C[4md[4ma[4mt[4ma[4m/[4my[4mc[4mm[4m/[4mi[4mn[4mp[4mu[4mt[4m2[4m.[4mw[4ma[4mv[24m[8C[4me[4mx[4mp[4ms[4m/[4mb[4mz[4mn[4m_[4mm[4mo[4md[4me[4ml[4m_[4mr[4me[4ms[4m/[4mb[4mn[4mf[4m-[4mv[4mc[4m-[4mt[4mo[4m-[4mo[4mn[4me[4m-[4mr[4me[4ms[4m-[4m4[4m4[4m.[4mp[4mt[24m[31C[?1l>[?25l[?2004lMM[0m[23m[24m[J[0m[49m[23m[24m[39m‚ùØ[0m[49m[39m[23m[24m CUDA_VISIBLE_DEVICES=0 [32mpython[39m [4minference_to_one.py[24m --src_wav [4mdata/ycm/input2.wav[24m --ckpt [4mexps/bzn_model_res/bnf-vc-to-one-r[4me[4ms-44.pt[24m --save_dir data/ycm/output_res[K[?25h
kpython\Set up BNFs extraction network
Loading BNFs extractor from ./config/asr_config.yaml
read 351 lines from ./pretrained_model/asr_model/dict.txt
example(last) <sos/eos> 350

init praat-f0 extractor with 20/600
Traceback (most recent call last):
  File "inference_to_one.py", line 69, in <module>
    main()
  File "inference_to_one.py", line 52, in main
    model.load_state_dict(torch.load(args.ckpt, map_location=device))
  File "/home/ycm/program_files/miniconda3/envs/dpss/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1406, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for BLSTMConversionModel:
	Unexpected key(s) in state_dict: "resnet.kan.layers.0.layernorm.weight", "resnet.kan.layers.0.layernorm.bias", "resnet.kan.layers.0.rbf.grid", "resnet.kan.layers.0.spline_linear.weight", "resnet.kan.layers.0.base_linear.weight", "resnet.kan.layers.0.base_linear.bias", "resnet.kan.layers.1.layernorm.weight", "resnet.kan.layers.1.layernorm.bias", "resnet.kan.layers.1.rbf.grid", "resnet.kan.layers.1.spline_linear.weight", "resnet.kan.layers.1.base_linear.weight", "resnet.kan.layers.1.base_linear.bias". 
[1m[3m%[23m[1m[0m                                                                                                                           k..s-exp3-VC-BNF\[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/[39mcou[0m[49m[39m/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°3 [39m!2 [39m?2[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?1h=[?2004h
bracketed-paste-magic:zle:47: not enough arguments for -U
[0m[23m[24m[J[0m[49m[39m
M[39m‚ï≠‚îÄ[0m[49m[30m [0m[30m[49m[39mÔåõ [0m[49m[39m[0m[49m [0m[49m[39mÔÅº  [1m[39m~[0m[49m[39m/[39mr[0m[49m[39m/[39mcou[0m[49m[39m/[1m[39mdpss-exp3-VC-BNF[0m[49m[39m[0m[49m[39m[0m[49m [0m[49m[39m[39mon [0m[49m[39mÔÑì [0m[49m[39m [39mÔÑ¶ master [39m‚á°3 [39m!2 [39m?2[0m[49m[39m[0m[49m[30m [0m[30m[49m[39m[39m
[0m[49m[39m[39m‚ï∞‚îÄ[0m[49m[39m‚ùØ[0m[49m[39m[0m[49m[30m[0m[30m[49m[39m [0m[49m[39m[K[?2004l

Script done on 2024-12-25 21:28:35+0800
